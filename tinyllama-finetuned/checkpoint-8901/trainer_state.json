{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 50,
  "global_step": 8901,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0011234692731153803,
      "grad_norm": 6.147064685821533,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 5.4309,
      "step": 10
    },
    {
      "epoch": 0.0022469385462307607,
      "grad_norm": 6.12493371963501,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 5.4213,
      "step": 20
    },
    {
      "epoch": 0.003370407819346141,
      "grad_norm": 6.197015762329102,
      "learning_rate": 5.8e-06,
      "loss": 5.0878,
      "step": 30
    },
    {
      "epoch": 0.004493877092461521,
      "grad_norm": 6.674697399139404,
      "learning_rate": 7.800000000000002e-06,
      "loss": 5.5122,
      "step": 40
    },
    {
      "epoch": 0.005617346365576902,
      "grad_norm": 11.627708435058594,
      "learning_rate": 9.800000000000001e-06,
      "loss": 5.4518,
      "step": 50
    },
    {
      "epoch": 0.006740815638692282,
      "grad_norm": 5.246941566467285,
      "learning_rate": 9.999974488281034e-06,
      "loss": 5.2955,
      "step": 60
    },
    {
      "epoch": 0.007864284911807662,
      "grad_norm": 7.432472229003906,
      "learning_rate": 9.999886299957119e-06,
      "loss": 5.1672,
      "step": 70
    },
    {
      "epoch": 0.008987754184923043,
      "grad_norm": 13.107882499694824,
      "learning_rate": 9.999735121179521e-06,
      "loss": 4.9816,
      "step": 80
    },
    {
      "epoch": 0.010111223458038422,
      "grad_norm": 4.429906368255615,
      "learning_rate": 9.999520953852853e-06,
      "loss": 5.0908,
      "step": 90
    },
    {
      "epoch": 0.011234692731153803,
      "grad_norm": 9.19766902923584,
      "learning_rate": 9.999243800675271e-06,
      "loss": 4.8708,
      "step": 100
    },
    {
      "epoch": 0.012358162004269183,
      "grad_norm": 7.929746627807617,
      "learning_rate": 9.99890366513846e-06,
      "loss": 4.685,
      "step": 110
    },
    {
      "epoch": 0.013481631277384564,
      "grad_norm": 6.457077503204346,
      "learning_rate": 9.998500551527573e-06,
      "loss": 5.1817,
      "step": 120
    },
    {
      "epoch": 0.014605100550499944,
      "grad_norm": 7.713522434234619,
      "learning_rate": 9.998034464921187e-06,
      "loss": 4.8121,
      "step": 130
    },
    {
      "epoch": 0.015728569823615323,
      "grad_norm": 8.801785469055176,
      "learning_rate": 9.997505411191237e-06,
      "loss": 4.3229,
      "step": 140
    },
    {
      "epoch": 0.016852039096730706,
      "grad_norm": 4.482691764831543,
      "learning_rate": 9.996913397002944e-06,
      "loss": 4.1748,
      "step": 150
    },
    {
      "epoch": 0.017975508369846085,
      "grad_norm": 8.655818939208984,
      "learning_rate": 9.996258429814724e-06,
      "loss": 4.3178,
      "step": 160
    },
    {
      "epoch": 0.019098977642961465,
      "grad_norm": 8.802157402038574,
      "learning_rate": 9.995540517878101e-06,
      "loss": 3.9177,
      "step": 170
    },
    {
      "epoch": 0.020222446916076844,
      "grad_norm": 13.215906143188477,
      "learning_rate": 9.994759670237599e-06,
      "loss": 3.6624,
      "step": 180
    },
    {
      "epoch": 0.021345916189192224,
      "grad_norm": 8.625152587890625,
      "learning_rate": 9.993915896730636e-06,
      "loss": 3.6554,
      "step": 190
    },
    {
      "epoch": 0.022469385462307607,
      "grad_norm": 6.206421375274658,
      "learning_rate": 9.99300920798738e-06,
      "loss": 3.6561,
      "step": 200
    },
    {
      "epoch": 0.023592854735422986,
      "grad_norm": 10.525282859802246,
      "learning_rate": 9.992039615430648e-06,
      "loss": 3.4238,
      "step": 210
    },
    {
      "epoch": 0.024716324008538366,
      "grad_norm": 9.998112678527832,
      "learning_rate": 9.991007131275726e-06,
      "loss": 3.47,
      "step": 220
    },
    {
      "epoch": 0.025839793281653745,
      "grad_norm": 11.132848739624023,
      "learning_rate": 9.989911768530241e-06,
      "loss": 3.2436,
      "step": 230
    },
    {
      "epoch": 0.026963262554769128,
      "grad_norm": 7.796259880065918,
      "learning_rate": 9.988753540993987e-06,
      "loss": 2.7688,
      "step": 240
    },
    {
      "epoch": 0.028086731827884508,
      "grad_norm": 6.741878986358643,
      "learning_rate": 9.98753246325875e-06,
      "loss": 3.0159,
      "step": 250
    },
    {
      "epoch": 0.029210201100999887,
      "grad_norm": 6.740501880645752,
      "learning_rate": 9.986248550708126e-06,
      "loss": 2.8023,
      "step": 260
    },
    {
      "epoch": 0.030333670374115267,
      "grad_norm": 4.669875621795654,
      "learning_rate": 9.984901819517334e-06,
      "loss": 2.6822,
      "step": 270
    },
    {
      "epoch": 0.031457139647230646,
      "grad_norm": 7.396091938018799,
      "learning_rate": 9.983492286653e-06,
      "loss": 2.6745,
      "step": 280
    },
    {
      "epoch": 0.032580608920346026,
      "grad_norm": 5.2347846031188965,
      "learning_rate": 9.982019969872949e-06,
      "loss": 2.7352,
      "step": 290
    },
    {
      "epoch": 0.03370407819346141,
      "grad_norm": 6.476300239562988,
      "learning_rate": 9.980484887725985e-06,
      "loss": 2.2694,
      "step": 300
    },
    {
      "epoch": 0.03482754746657679,
      "grad_norm": 5.908883571624756,
      "learning_rate": 9.978887059551652e-06,
      "loss": 2.6951,
      "step": 310
    },
    {
      "epoch": 0.03595101673969217,
      "grad_norm": 11.7717924118042,
      "learning_rate": 9.97722650547999e-06,
      "loss": 2.9862,
      "step": 320
    },
    {
      "epoch": 0.03707448601280755,
      "grad_norm": 6.62354040145874,
      "learning_rate": 9.975503246431288e-06,
      "loss": 2.4744,
      "step": 330
    },
    {
      "epoch": 0.03819795528592293,
      "grad_norm": 8.13861083984375,
      "learning_rate": 9.973717304115813e-06,
      "loss": 2.7346,
      "step": 340
    },
    {
      "epoch": 0.03932142455903831,
      "grad_norm": 6.143515586853027,
      "learning_rate": 9.971868701033538e-06,
      "loss": 2.4838,
      "step": 350
    },
    {
      "epoch": 0.04044489383215369,
      "grad_norm": 6.321849346160889,
      "learning_rate": 9.969957460473865e-06,
      "loss": 2.4072,
      "step": 360
    },
    {
      "epoch": 0.04156836310526907,
      "grad_norm": 13.171258926391602,
      "learning_rate": 9.967983606515321e-06,
      "loss": 2.5626,
      "step": 370
    },
    {
      "epoch": 0.04269183237838445,
      "grad_norm": 5.434675693511963,
      "learning_rate": 9.965947164025265e-06,
      "loss": 2.3623,
      "step": 380
    },
    {
      "epoch": 0.043815301651499834,
      "grad_norm": 5.7421746253967285,
      "learning_rate": 9.963848158659567e-06,
      "loss": 2.6412,
      "step": 390
    },
    {
      "epoch": 0.044938770924615214,
      "grad_norm": 5.404590129852295,
      "learning_rate": 9.961686616862284e-06,
      "loss": 2.1562,
      "step": 400
    },
    {
      "epoch": 0.04606224019773059,
      "grad_norm": 9.287324905395508,
      "learning_rate": 9.959462565865344e-06,
      "loss": 2.3059,
      "step": 410
    },
    {
      "epoch": 0.04718570947084597,
      "grad_norm": 6.194969654083252,
      "learning_rate": 9.957176033688172e-06,
      "loss": 2.2632,
      "step": 420
    },
    {
      "epoch": 0.04830917874396135,
      "grad_norm": 8.226783752441406,
      "learning_rate": 9.954827049137366e-06,
      "loss": 2.4903,
      "step": 430
    },
    {
      "epoch": 0.04943264801707673,
      "grad_norm": 6.006326198577881,
      "learning_rate": 9.952415641806321e-06,
      "loss": 2.2068,
      "step": 440
    },
    {
      "epoch": 0.05055611729019211,
      "grad_norm": 5.499244689941406,
      "learning_rate": 9.949941842074855e-06,
      "loss": 2.6464,
      "step": 450
    },
    {
      "epoch": 0.05167958656330749,
      "grad_norm": 5.751840591430664,
      "learning_rate": 9.947405681108828e-06,
      "loss": 2.4744,
      "step": 460
    },
    {
      "epoch": 0.05280305583642288,
      "grad_norm": 5.752479076385498,
      "learning_rate": 9.944807190859758e-06,
      "loss": 2.3282,
      "step": 470
    },
    {
      "epoch": 0.053926525109538256,
      "grad_norm": 23.914878845214844,
      "learning_rate": 9.9421464040644e-06,
      "loss": 2.2072,
      "step": 480
    },
    {
      "epoch": 0.055049994382653636,
      "grad_norm": 7.34202766418457,
      "learning_rate": 9.93942335424435e-06,
      "loss": 2.3636,
      "step": 490
    },
    {
      "epoch": 0.056173463655769015,
      "grad_norm": 4.969516754150391,
      "learning_rate": 9.93663807570562e-06,
      "loss": 1.9556,
      "step": 500
    },
    {
      "epoch": 0.057296932928884395,
      "grad_norm": 8.472620010375977,
      "learning_rate": 9.9337906035382e-06,
      "loss": 2.2169,
      "step": 510
    },
    {
      "epoch": 0.058420402201999774,
      "grad_norm": 5.856889247894287,
      "learning_rate": 9.930880973615615e-06,
      "loss": 2.1456,
      "step": 520
    },
    {
      "epoch": 0.059543871475115154,
      "grad_norm": 9.67652702331543,
      "learning_rate": 9.927909222594482e-06,
      "loss": 2.1773,
      "step": 530
    },
    {
      "epoch": 0.06066734074823053,
      "grad_norm": 10.436868667602539,
      "learning_rate": 9.924875387914041e-06,
      "loss": 1.9053,
      "step": 540
    },
    {
      "epoch": 0.06179081002134592,
      "grad_norm": 7.9487175941467285,
      "learning_rate": 9.921779507795687e-06,
      "loss": 2.1599,
      "step": 550
    },
    {
      "epoch": 0.06291427929446129,
      "grad_norm": 22.20844078063965,
      "learning_rate": 9.918621621242486e-06,
      "loss": 2.2519,
      "step": 560
    },
    {
      "epoch": 0.06403774856757667,
      "grad_norm": 7.535541534423828,
      "learning_rate": 9.915401768038681e-06,
      "loss": 2.4653,
      "step": 570
    },
    {
      "epoch": 0.06516121784069205,
      "grad_norm": 6.000051975250244,
      "learning_rate": 9.9121199887492e-06,
      "loss": 1.9195,
      "step": 580
    },
    {
      "epoch": 0.06628468711380743,
      "grad_norm": 14.802098274230957,
      "learning_rate": 9.908776324719133e-06,
      "loss": 1.9541,
      "step": 590
    },
    {
      "epoch": 0.06740815638692282,
      "grad_norm": 7.557612895965576,
      "learning_rate": 9.905370818073226e-06,
      "loss": 1.9044,
      "step": 600
    },
    {
      "epoch": 0.0685316256600382,
      "grad_norm": 7.102180480957031,
      "learning_rate": 9.901903511715333e-06,
      "loss": 2.116,
      "step": 610
    },
    {
      "epoch": 0.06965509493315358,
      "grad_norm": 23.88744354248047,
      "learning_rate": 9.898374449327887e-06,
      "loss": 1.9336,
      "step": 620
    },
    {
      "epoch": 0.07077856420626896,
      "grad_norm": 7.655656337738037,
      "learning_rate": 9.89478367537135e-06,
      "loss": 1.9156,
      "step": 630
    },
    {
      "epoch": 0.07190203347938434,
      "grad_norm": 8.210565567016602,
      "learning_rate": 9.891131235083644e-06,
      "loss": 2.2073,
      "step": 640
    },
    {
      "epoch": 0.07302550275249972,
      "grad_norm": 6.198691368103027,
      "learning_rate": 9.887417174479591e-06,
      "loss": 2.0027,
      "step": 650
    },
    {
      "epoch": 0.0741489720256151,
      "grad_norm": 5.7767815589904785,
      "learning_rate": 9.883641540350327e-06,
      "loss": 2.2029,
      "step": 660
    },
    {
      "epoch": 0.07527244129873048,
      "grad_norm": 6.165176868438721,
      "learning_rate": 9.879804380262715e-06,
      "loss": 1.9718,
      "step": 670
    },
    {
      "epoch": 0.07639591057184586,
      "grad_norm": 5.896076679229736,
      "learning_rate": 9.875905742558745e-06,
      "loss": 2.2309,
      "step": 680
    },
    {
      "epoch": 0.07751937984496124,
      "grad_norm": 14.142913818359375,
      "learning_rate": 9.871945676354927e-06,
      "loss": 2.175,
      "step": 690
    },
    {
      "epoch": 0.07864284911807662,
      "grad_norm": 6.359431266784668,
      "learning_rate": 9.867924231541669e-06,
      "loss": 2.0531,
      "step": 700
    },
    {
      "epoch": 0.079766318391192,
      "grad_norm": 8.089859008789062,
      "learning_rate": 9.863841458782645e-06,
      "loss": 1.7685,
      "step": 710
    },
    {
      "epoch": 0.08088978766430738,
      "grad_norm": 7.4014811515808105,
      "learning_rate": 9.85969740951417e-06,
      "loss": 1.924,
      "step": 720
    },
    {
      "epoch": 0.08201325693742276,
      "grad_norm": 10.89830493927002,
      "learning_rate": 9.855492135944542e-06,
      "loss": 2.0522,
      "step": 730
    },
    {
      "epoch": 0.08313672621053814,
      "grad_norm": 19.414440155029297,
      "learning_rate": 9.851225691053382e-06,
      "loss": 2.2719,
      "step": 740
    },
    {
      "epoch": 0.08426019548365352,
      "grad_norm": 6.270463466644287,
      "learning_rate": 9.846898128590969e-06,
      "loss": 2.0583,
      "step": 750
    },
    {
      "epoch": 0.0853836647567689,
      "grad_norm": 5.623737335205078,
      "learning_rate": 9.842509503077571e-06,
      "loss": 1.8327,
      "step": 760
    },
    {
      "epoch": 0.08650713402988429,
      "grad_norm": 9.210576057434082,
      "learning_rate": 9.838059869802746e-06,
      "loss": 2.102,
      "step": 770
    },
    {
      "epoch": 0.08763060330299967,
      "grad_norm": 11.857507705688477,
      "learning_rate": 9.833549284824655e-06,
      "loss": 1.9768,
      "step": 780
    },
    {
      "epoch": 0.08875407257611505,
      "grad_norm": 13.712220191955566,
      "learning_rate": 9.828977804969346e-06,
      "loss": 1.6739,
      "step": 790
    },
    {
      "epoch": 0.08987754184923043,
      "grad_norm": 7.643710136413574,
      "learning_rate": 9.824345487830047e-06,
      "loss": 2.1352,
      "step": 800
    },
    {
      "epoch": 0.0910010111223458,
      "grad_norm": 6.135042190551758,
      "learning_rate": 9.819652391766439e-06,
      "loss": 2.0283,
      "step": 810
    },
    {
      "epoch": 0.09212448039546119,
      "grad_norm": 4.660433769226074,
      "learning_rate": 9.814898575903916e-06,
      "loss": 2.1639,
      "step": 820
    },
    {
      "epoch": 0.09324794966857657,
      "grad_norm": 5.837576866149902,
      "learning_rate": 9.81008410013284e-06,
      "loss": 2.1013,
      "step": 830
    },
    {
      "epoch": 0.09437141894169195,
      "grad_norm": 9.604622840881348,
      "learning_rate": 9.805209025107798e-06,
      "loss": 2.0537,
      "step": 840
    },
    {
      "epoch": 0.09549488821480732,
      "grad_norm": 8.0236177444458,
      "learning_rate": 9.800273412246822e-06,
      "loss": 1.9846,
      "step": 850
    },
    {
      "epoch": 0.0966183574879227,
      "grad_norm": 4.876420497894287,
      "learning_rate": 9.795277323730622e-06,
      "loss": 2.2906,
      "step": 860
    },
    {
      "epoch": 0.09774182676103808,
      "grad_norm": 16.585081100463867,
      "learning_rate": 9.79022082250181e-06,
      "loss": 1.9856,
      "step": 870
    },
    {
      "epoch": 0.09886529603415346,
      "grad_norm": 12.62175464630127,
      "learning_rate": 9.785103972264092e-06,
      "loss": 2.1272,
      "step": 880
    },
    {
      "epoch": 0.09998876530726884,
      "grad_norm": 5.331020355224609,
      "learning_rate": 9.779926837481482e-06,
      "loss": 2.0597,
      "step": 890
    },
    {
      "epoch": 0.10111223458038422,
      "grad_norm": 6.190315246582031,
      "learning_rate": 9.774689483377472e-06,
      "loss": 2.0338,
      "step": 900
    },
    {
      "epoch": 0.1022357038534996,
      "grad_norm": 10.425010681152344,
      "learning_rate": 9.76939197593423e-06,
      "loss": 2.1201,
      "step": 910
    },
    {
      "epoch": 0.10335917312661498,
      "grad_norm": 6.584572792053223,
      "learning_rate": 9.76403438189175e-06,
      "loss": 2.2197,
      "step": 920
    },
    {
      "epoch": 0.10448264239973036,
      "grad_norm": 4.964018821716309,
      "learning_rate": 9.758616768747022e-06,
      "loss": 1.6781,
      "step": 930
    },
    {
      "epoch": 0.10560611167284575,
      "grad_norm": 5.156727313995361,
      "learning_rate": 9.75313920475318e-06,
      "loss": 2.0585,
      "step": 940
    },
    {
      "epoch": 0.10672958094596113,
      "grad_norm": 7.111324310302734,
      "learning_rate": 9.747601758918643e-06,
      "loss": 1.6581,
      "step": 950
    },
    {
      "epoch": 0.10785305021907651,
      "grad_norm": 5.971310138702393,
      "learning_rate": 9.742004501006243e-06,
      "loss": 1.5799,
      "step": 960
    },
    {
      "epoch": 0.10897651949219189,
      "grad_norm": 7.225564479827881,
      "learning_rate": 9.736347501532345e-06,
      "loss": 2.0007,
      "step": 970
    },
    {
      "epoch": 0.11009998876530727,
      "grad_norm": 5.161186218261719,
      "learning_rate": 9.730630831765963e-06,
      "loss": 1.7795,
      "step": 980
    },
    {
      "epoch": 0.11122345803842265,
      "grad_norm": 9.499883651733398,
      "learning_rate": 9.724854563727858e-06,
      "loss": 1.7724,
      "step": 990
    },
    {
      "epoch": 0.11234692731153803,
      "grad_norm": 15.650410652160645,
      "learning_rate": 9.719018770189636e-06,
      "loss": 2.0668,
      "step": 1000
    },
    {
      "epoch": 0.11347039658465341,
      "grad_norm": 8.428664207458496,
      "learning_rate": 9.713123524672826e-06,
      "loss": 1.8856,
      "step": 1010
    },
    {
      "epoch": 0.11459386585776879,
      "grad_norm": 12.707174301147461,
      "learning_rate": 9.70716890144795e-06,
      "loss": 2.1626,
      "step": 1020
    },
    {
      "epoch": 0.11571733513088417,
      "grad_norm": 4.428234100341797,
      "learning_rate": 9.7011549755336e-06,
      "loss": 1.6099,
      "step": 1030
    },
    {
      "epoch": 0.11684080440399955,
      "grad_norm": 7.584407329559326,
      "learning_rate": 9.695081822695486e-06,
      "loss": 2.0917,
      "step": 1040
    },
    {
      "epoch": 0.11796427367711493,
      "grad_norm": 20.168365478515625,
      "learning_rate": 9.688949519445476e-06,
      "loss": 2.5232,
      "step": 1050
    },
    {
      "epoch": 0.11908774295023031,
      "grad_norm": 7.265089988708496,
      "learning_rate": 9.682758143040639e-06,
      "loss": 1.5344,
      "step": 1060
    },
    {
      "epoch": 0.12021121222334569,
      "grad_norm": 8.61964225769043,
      "learning_rate": 9.676507771482273e-06,
      "loss": 1.9349,
      "step": 1070
    },
    {
      "epoch": 0.12133468149646107,
      "grad_norm": 9.404589653015137,
      "learning_rate": 9.670198483514913e-06,
      "loss": 2.0077,
      "step": 1080
    },
    {
      "epoch": 0.12245815076957645,
      "grad_norm": 5.444838047027588,
      "learning_rate": 9.663830358625352e-06,
      "loss": 2.0181,
      "step": 1090
    },
    {
      "epoch": 0.12358162004269184,
      "grad_norm": 5.172971725463867,
      "learning_rate": 9.657403477041627e-06,
      "loss": 2.1606,
      "step": 1100
    },
    {
      "epoch": 0.12470508931580722,
      "grad_norm": 6.350484371185303,
      "learning_rate": 9.650917919732019e-06,
      "loss": 1.9807,
      "step": 1110
    },
    {
      "epoch": 0.12582855858892258,
      "grad_norm": 11.218440055847168,
      "learning_rate": 9.644373768404025e-06,
      "loss": 2.0013,
      "step": 1120
    },
    {
      "epoch": 0.12695202786203796,
      "grad_norm": 6.347531318664551,
      "learning_rate": 9.63777110550333e-06,
      "loss": 1.9655,
      "step": 1130
    },
    {
      "epoch": 0.12807549713515334,
      "grad_norm": 17.696962356567383,
      "learning_rate": 9.631110014212775e-06,
      "loss": 1.921,
      "step": 1140
    },
    {
      "epoch": 0.12919896640826872,
      "grad_norm": 14.71638298034668,
      "learning_rate": 9.624390578451298e-06,
      "loss": 1.5609,
      "step": 1150
    },
    {
      "epoch": 0.1303224356813841,
      "grad_norm": 12.480271339416504,
      "learning_rate": 9.617612882872887e-06,
      "loss": 2.6689,
      "step": 1160
    },
    {
      "epoch": 0.13144590495449948,
      "grad_norm": 5.0791730880737305,
      "learning_rate": 9.610777012865507e-06,
      "loss": 1.6775,
      "step": 1170
    },
    {
      "epoch": 0.13256937422761486,
      "grad_norm": 4.882651329040527,
      "learning_rate": 9.603883054550028e-06,
      "loss": 1.691,
      "step": 1180
    },
    {
      "epoch": 0.13369284350073027,
      "grad_norm": 6.840871334075928,
      "learning_rate": 9.596931094779136e-06,
      "loss": 2.0127,
      "step": 1190
    },
    {
      "epoch": 0.13481631277384565,
      "grad_norm": 7.826768398284912,
      "learning_rate": 9.589921221136242e-06,
      "loss": 1.6105,
      "step": 1200
    },
    {
      "epoch": 0.13593978204696103,
      "grad_norm": 14.68922233581543,
      "learning_rate": 9.582853521934383e-06,
      "loss": 2.0454,
      "step": 1210
    },
    {
      "epoch": 0.1370632513200764,
      "grad_norm": 8.541604042053223,
      "learning_rate": 9.575728086215093e-06,
      "loss": 2.2917,
      "step": 1220
    },
    {
      "epoch": 0.1381867205931918,
      "grad_norm": 6.346184253692627,
      "learning_rate": 9.568545003747304e-06,
      "loss": 1.8407,
      "step": 1230
    },
    {
      "epoch": 0.13931018986630717,
      "grad_norm": 7.253042221069336,
      "learning_rate": 9.561304365026196e-06,
      "loss": 1.8108,
      "step": 1240
    },
    {
      "epoch": 0.14043365913942255,
      "grad_norm": 6.758986473083496,
      "learning_rate": 9.554006261272068e-06,
      "loss": 1.7729,
      "step": 1250
    },
    {
      "epoch": 0.14155712841253792,
      "grad_norm": 8.051626205444336,
      "learning_rate": 9.546650784429185e-06,
      "loss": 1.9113,
      "step": 1260
    },
    {
      "epoch": 0.1426805976856533,
      "grad_norm": 8.604259490966797,
      "learning_rate": 9.539238027164618e-06,
      "loss": 1.7998,
      "step": 1270
    },
    {
      "epoch": 0.14380406695876868,
      "grad_norm": 6.552241802215576,
      "learning_rate": 9.53176808286708e-06,
      "loss": 1.9902,
      "step": 1280
    },
    {
      "epoch": 0.14492753623188406,
      "grad_norm": 4.678679943084717,
      "learning_rate": 9.524241045645747e-06,
      "loss": 2.3248,
      "step": 1290
    },
    {
      "epoch": 0.14605100550499944,
      "grad_norm": 6.001018524169922,
      "learning_rate": 9.51665701032907e-06,
      "loss": 1.65,
      "step": 1300
    },
    {
      "epoch": 0.14717447477811482,
      "grad_norm": 6.898464202880859,
      "learning_rate": 9.509016072463588e-06,
      "loss": 1.868,
      "step": 1310
    },
    {
      "epoch": 0.1482979440512302,
      "grad_norm": 13.756660461425781,
      "learning_rate": 9.501318328312722e-06,
      "loss": 2.1371,
      "step": 1320
    },
    {
      "epoch": 0.14942141332434558,
      "grad_norm": 7.495137691497803,
      "learning_rate": 9.493563874855556e-06,
      "loss": 1.9509,
      "step": 1330
    },
    {
      "epoch": 0.15054488259746096,
      "grad_norm": 5.992722988128662,
      "learning_rate": 9.485752809785617e-06,
      "loss": 2.0941,
      "step": 1340
    },
    {
      "epoch": 0.15166835187057634,
      "grad_norm": 10.733536720275879,
      "learning_rate": 9.477885231509651e-06,
      "loss": 2.3407,
      "step": 1350
    },
    {
      "epoch": 0.15279182114369172,
      "grad_norm": 8.602091789245605,
      "learning_rate": 9.469961239146377e-06,
      "loss": 1.9974,
      "step": 1360
    },
    {
      "epoch": 0.1539152904168071,
      "grad_norm": 7.719170093536377,
      "learning_rate": 9.461980932525238e-06,
      "loss": 2.189,
      "step": 1370
    },
    {
      "epoch": 0.15503875968992248,
      "grad_norm": 7.314300537109375,
      "learning_rate": 9.45394441218515e-06,
      "loss": 1.9291,
      "step": 1380
    },
    {
      "epoch": 0.15616222896303786,
      "grad_norm": 5.363766193389893,
      "learning_rate": 9.445851779373226e-06,
      "loss": 2.1925,
      "step": 1390
    },
    {
      "epoch": 0.15728569823615324,
      "grad_norm": 11.157465934753418,
      "learning_rate": 9.437703136043508e-06,
      "loss": 2.4696,
      "step": 1400
    },
    {
      "epoch": 0.15840916750926862,
      "grad_norm": 6.235458850860596,
      "learning_rate": 9.429498584855677e-06,
      "loss": 1.7612,
      "step": 1410
    },
    {
      "epoch": 0.159532636782384,
      "grad_norm": 7.741106033325195,
      "learning_rate": 9.421238229173764e-06,
      "loss": 1.9242,
      "step": 1420
    },
    {
      "epoch": 0.16065610605549938,
      "grad_norm": 5.989582061767578,
      "learning_rate": 9.412922173064848e-06,
      "loss": 1.9549,
      "step": 1430
    },
    {
      "epoch": 0.16177957532861476,
      "grad_norm": 6.733628749847412,
      "learning_rate": 9.40455052129774e-06,
      "loss": 2.1884,
      "step": 1440
    },
    {
      "epoch": 0.16290304460173013,
      "grad_norm": 10.063029289245605,
      "learning_rate": 9.396123379341663e-06,
      "loss": 1.8134,
      "step": 1450
    },
    {
      "epoch": 0.16402651387484551,
      "grad_norm": 6.433215618133545,
      "learning_rate": 9.387640853364938e-06,
      "loss": 1.955,
      "step": 1460
    },
    {
      "epoch": 0.1651499831479609,
      "grad_norm": 4.26019811630249,
      "learning_rate": 9.37910305023362e-06,
      "loss": 2.0574,
      "step": 1470
    },
    {
      "epoch": 0.16627345242107627,
      "grad_norm": 9.574649810791016,
      "learning_rate": 9.370510077510178e-06,
      "loss": 1.9881,
      "step": 1480
    },
    {
      "epoch": 0.16739692169419165,
      "grad_norm": 14.285786628723145,
      "learning_rate": 9.36186204345212e-06,
      "loss": 1.8322,
      "step": 1490
    },
    {
      "epoch": 0.16852039096730703,
      "grad_norm": 6.732466697692871,
      "learning_rate": 9.353159057010645e-06,
      "loss": 1.8241,
      "step": 1500
    },
    {
      "epoch": 0.1696438602404224,
      "grad_norm": 8.919678688049316,
      "learning_rate": 9.344401227829256e-06,
      "loss": 2.1002,
      "step": 1510
    },
    {
      "epoch": 0.1707673295135378,
      "grad_norm": 6.678176403045654,
      "learning_rate": 9.335588666242392e-06,
      "loss": 1.8251,
      "step": 1520
    },
    {
      "epoch": 0.1718907987866532,
      "grad_norm": 7.588658332824707,
      "learning_rate": 9.326721483274025e-06,
      "loss": 1.9319,
      "step": 1530
    },
    {
      "epoch": 0.17301426805976858,
      "grad_norm": 7.250946998596191,
      "learning_rate": 9.317799790636272e-06,
      "loss": 1.8391,
      "step": 1540
    },
    {
      "epoch": 0.17413773733288396,
      "grad_norm": 13.796674728393555,
      "learning_rate": 9.308823700727985e-06,
      "loss": 1.9357,
      "step": 1550
    },
    {
      "epoch": 0.17526120660599934,
      "grad_norm": 6.757290840148926,
      "learning_rate": 9.299793326633326e-06,
      "loss": 1.8157,
      "step": 1560
    },
    {
      "epoch": 0.17638467587911472,
      "grad_norm": 7.536008358001709,
      "learning_rate": 9.290708782120358e-06,
      "loss": 2.2552,
      "step": 1570
    },
    {
      "epoch": 0.1775081451522301,
      "grad_norm": 30.979734420776367,
      "learning_rate": 9.281570181639597e-06,
      "loss": 2.2626,
      "step": 1580
    },
    {
      "epoch": 0.17863161442534548,
      "grad_norm": 9.183650016784668,
      "learning_rate": 9.272377640322581e-06,
      "loss": 1.5448,
      "step": 1590
    },
    {
      "epoch": 0.17975508369846085,
      "grad_norm": 9.350935935974121,
      "learning_rate": 9.263131273980414e-06,
      "loss": 1.2635,
      "step": 1600
    },
    {
      "epoch": 0.18087855297157623,
      "grad_norm": 5.9690093994140625,
      "learning_rate": 9.253831199102303e-06,
      "loss": 1.5174,
      "step": 1610
    },
    {
      "epoch": 0.1820020222446916,
      "grad_norm": 5.306458950042725,
      "learning_rate": 9.244477532854104e-06,
      "loss": 1.6623,
      "step": 1620
    },
    {
      "epoch": 0.183125491517807,
      "grad_norm": 6.3677825927734375,
      "learning_rate": 9.235070393076832e-06,
      "loss": 2.1313,
      "step": 1630
    },
    {
      "epoch": 0.18424896079092237,
      "grad_norm": 5.905651569366455,
      "learning_rate": 9.22560989828518e-06,
      "loss": 2.0055,
      "step": 1640
    },
    {
      "epoch": 0.18537243006403775,
      "grad_norm": 6.399147033691406,
      "learning_rate": 9.21609616766603e-06,
      "loss": 2.0056,
      "step": 1650
    },
    {
      "epoch": 0.18649589933715313,
      "grad_norm": 6.87803840637207,
      "learning_rate": 9.206529321076953e-06,
      "loss": 1.9414,
      "step": 1660
    },
    {
      "epoch": 0.1876193686102685,
      "grad_norm": 5.361389636993408,
      "learning_rate": 9.196909479044689e-06,
      "loss": 2.2322,
      "step": 1670
    },
    {
      "epoch": 0.1887428378833839,
      "grad_norm": 7.570377826690674,
      "learning_rate": 9.187236762763636e-06,
      "loss": 1.5474,
      "step": 1680
    },
    {
      "epoch": 0.18986630715649927,
      "grad_norm": 8.70011043548584,
      "learning_rate": 9.177511294094323e-06,
      "loss": 2.0898,
      "step": 1690
    },
    {
      "epoch": 0.19098977642961465,
      "grad_norm": 9.527329444885254,
      "learning_rate": 9.167733195561875e-06,
      "loss": 2.0091,
      "step": 1700
    },
    {
      "epoch": 0.19211324570273003,
      "grad_norm": 10.368678092956543,
      "learning_rate": 9.157902590354462e-06,
      "loss": 2.0584,
      "step": 1710
    },
    {
      "epoch": 0.1932367149758454,
      "grad_norm": 10.09080696105957,
      "learning_rate": 9.148019602321759e-06,
      "loss": 2.2522,
      "step": 1720
    },
    {
      "epoch": 0.1943601842489608,
      "grad_norm": 12.602091789245605,
      "learning_rate": 9.138084355973378e-06,
      "loss": 2.1422,
      "step": 1730
    },
    {
      "epoch": 0.19548365352207617,
      "grad_norm": 15.21805477142334,
      "learning_rate": 9.128096976477299e-06,
      "loss": 2.191,
      "step": 1740
    },
    {
      "epoch": 0.19660712279519155,
      "grad_norm": 24.449914932250977,
      "learning_rate": 9.118057589658296e-06,
      "loss": 1.9677,
      "step": 1750
    },
    {
      "epoch": 0.19773059206830693,
      "grad_norm": 7.519408702850342,
      "learning_rate": 9.107966321996351e-06,
      "loss": 2.3857,
      "step": 1760
    },
    {
      "epoch": 0.1988540613414223,
      "grad_norm": 16.331697463989258,
      "learning_rate": 9.097823300625063e-06,
      "loss": 1.7607,
      "step": 1770
    },
    {
      "epoch": 0.19997753061453769,
      "grad_norm": 7.6597580909729,
      "learning_rate": 9.08762865333004e-06,
      "loss": 1.9666,
      "step": 1780
    },
    {
      "epoch": 0.20110099988765306,
      "grad_norm": 6.10899543762207,
      "learning_rate": 9.077382508547294e-06,
      "loss": 1.8916,
      "step": 1790
    },
    {
      "epoch": 0.20222446916076844,
      "grad_norm": 11.03091049194336,
      "learning_rate": 9.067084995361623e-06,
      "loss": 2.2578,
      "step": 1800
    },
    {
      "epoch": 0.20334793843388382,
      "grad_norm": 6.5493998527526855,
      "learning_rate": 9.056736243504982e-06,
      "loss": 1.7857,
      "step": 1810
    },
    {
      "epoch": 0.2044714077069992,
      "grad_norm": 7.011531829833984,
      "learning_rate": 9.04633638335485e-06,
      "loss": 1.7754,
      "step": 1820
    },
    {
      "epoch": 0.20559487698011458,
      "grad_norm": 7.921724796295166,
      "learning_rate": 9.035885545932589e-06,
      "loss": 2.4432,
      "step": 1830
    },
    {
      "epoch": 0.20671834625322996,
      "grad_norm": 5.242003917694092,
      "learning_rate": 9.025383862901791e-06,
      "loss": 1.8589,
      "step": 1840
    },
    {
      "epoch": 0.20784181552634534,
      "grad_norm": 17.49629783630371,
      "learning_rate": 9.01483146656662e-06,
      "loss": 1.7606,
      "step": 1850
    },
    {
      "epoch": 0.20896528479946072,
      "grad_norm": 5.904458045959473,
      "learning_rate": 9.004228489870146e-06,
      "loss": 2.1571,
      "step": 1860
    },
    {
      "epoch": 0.21008875407257613,
      "grad_norm": 8.406074523925781,
      "learning_rate": 8.99357506639267e-06,
      "loss": 2.0058,
      "step": 1870
    },
    {
      "epoch": 0.2112122233456915,
      "grad_norm": 7.395989418029785,
      "learning_rate": 8.982871330350038e-06,
      "loss": 1.913,
      "step": 1880
    },
    {
      "epoch": 0.2123356926188069,
      "grad_norm": 5.700760364532471,
      "learning_rate": 8.972117416591954e-06,
      "loss": 1.9401,
      "step": 1890
    },
    {
      "epoch": 0.21345916189192227,
      "grad_norm": 6.940887928009033,
      "learning_rate": 8.961313460600283e-06,
      "loss": 2.0017,
      "step": 1900
    },
    {
      "epoch": 0.21458263116503765,
      "grad_norm": 8.229026794433594,
      "learning_rate": 8.950459598487336e-06,
      "loss": 1.7908,
      "step": 1910
    },
    {
      "epoch": 0.21570610043815303,
      "grad_norm": 8.773021697998047,
      "learning_rate": 8.939555966994161e-06,
      "loss": 1.8893,
      "step": 1920
    },
    {
      "epoch": 0.2168295697112684,
      "grad_norm": 12.28089427947998,
      "learning_rate": 8.928602703488823e-06,
      "loss": 2.0389,
      "step": 1930
    },
    {
      "epoch": 0.21795303898438378,
      "grad_norm": 35.251853942871094,
      "learning_rate": 8.917599945964667e-06,
      "loss": 2.3132,
      "step": 1940
    },
    {
      "epoch": 0.21907650825749916,
      "grad_norm": 5.573892593383789,
      "learning_rate": 8.906547833038583e-06,
      "loss": 1.8444,
      "step": 1950
    },
    {
      "epoch": 0.22019997753061454,
      "grad_norm": 7.733975410461426,
      "learning_rate": 8.895446503949257e-06,
      "loss": 1.9525,
      "step": 1960
    },
    {
      "epoch": 0.22132344680372992,
      "grad_norm": 7.236040115356445,
      "learning_rate": 8.884296098555422e-06,
      "loss": 1.8572,
      "step": 1970
    },
    {
      "epoch": 0.2224469160768453,
      "grad_norm": 9.62947940826416,
      "learning_rate": 8.873096757334092e-06,
      "loss": 1.7576,
      "step": 1980
    },
    {
      "epoch": 0.22357038534996068,
      "grad_norm": 7.872208118438721,
      "learning_rate": 8.861848621378791e-06,
      "loss": 1.6251,
      "step": 1990
    },
    {
      "epoch": 0.22469385462307606,
      "grad_norm": 10.226191520690918,
      "learning_rate": 8.85055183239778e-06,
      "loss": 1.967,
      "step": 2000
    },
    {
      "epoch": 0.22581732389619144,
      "grad_norm": 9.053391456604004,
      "learning_rate": 8.839206532712266e-06,
      "loss": 1.6553,
      "step": 2010
    },
    {
      "epoch": 0.22694079316930682,
      "grad_norm": 8.537017822265625,
      "learning_rate": 8.827812865254616e-06,
      "loss": 1.9384,
      "step": 2020
    },
    {
      "epoch": 0.2280642624424222,
      "grad_norm": 5.923064708709717,
      "learning_rate": 8.816370973566551e-06,
      "loss": 2.1824,
      "step": 2030
    },
    {
      "epoch": 0.22918773171553758,
      "grad_norm": 5.699684143066406,
      "learning_rate": 8.804881001797337e-06,
      "loss": 1.7714,
      "step": 2040
    },
    {
      "epoch": 0.23031120098865296,
      "grad_norm": 14.117365837097168,
      "learning_rate": 8.793343094701972e-06,
      "loss": 1.9615,
      "step": 2050
    },
    {
      "epoch": 0.23143467026176834,
      "grad_norm": 6.8386101722717285,
      "learning_rate": 8.781757397639363e-06,
      "loss": 2.0451,
      "step": 2060
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 6.847597599029541,
      "learning_rate": 8.770124056570493e-06,
      "loss": 2.0914,
      "step": 2070
    },
    {
      "epoch": 0.2336816088079991,
      "grad_norm": 19.570276260375977,
      "learning_rate": 8.75844321805658e-06,
      "loss": 1.7267,
      "step": 2080
    },
    {
      "epoch": 0.23480507808111448,
      "grad_norm": 8.190546035766602,
      "learning_rate": 8.746715029257236e-06,
      "loss": 2.3126,
      "step": 2090
    },
    {
      "epoch": 0.23592854735422986,
      "grad_norm": 11.371402740478516,
      "learning_rate": 8.734939637928604e-06,
      "loss": 2.234,
      "step": 2100
    },
    {
      "epoch": 0.23705201662734524,
      "grad_norm": 8.145200729370117,
      "learning_rate": 8.723117192421509e-06,
      "loss": 1.8812,
      "step": 2110
    },
    {
      "epoch": 0.23817548590046062,
      "grad_norm": 19.91832733154297,
      "learning_rate": 8.711247841679578e-06,
      "loss": 1.8995,
      "step": 2120
    },
    {
      "epoch": 0.239298955173576,
      "grad_norm": 7.3117756843566895,
      "learning_rate": 8.699331735237368e-06,
      "loss": 1.8305,
      "step": 2130
    },
    {
      "epoch": 0.24042242444669137,
      "grad_norm": 5.930131912231445,
      "learning_rate": 8.687369023218484e-06,
      "loss": 1.84,
      "step": 2140
    },
    {
      "epoch": 0.24154589371980675,
      "grad_norm": 8.643930435180664,
      "learning_rate": 8.675359856333685e-06,
      "loss": 2.5796,
      "step": 2150
    },
    {
      "epoch": 0.24266936299292213,
      "grad_norm": 4.972001552581787,
      "learning_rate": 8.663304385878986e-06,
      "loss": 1.8476,
      "step": 2160
    },
    {
      "epoch": 0.2437928322660375,
      "grad_norm": 12.58804988861084,
      "learning_rate": 8.651202763733748e-06,
      "loss": 1.769,
      "step": 2170
    },
    {
      "epoch": 0.2449163015391529,
      "grad_norm": 8.33725357055664,
      "learning_rate": 8.639055142358778e-06,
      "loss": 1.7202,
      "step": 2180
    },
    {
      "epoch": 0.24603977081226827,
      "grad_norm": 10.154464721679688,
      "learning_rate": 8.626861674794386e-06,
      "loss": 2.3908,
      "step": 2190
    },
    {
      "epoch": 0.24716324008538368,
      "grad_norm": 8.26225757598877,
      "learning_rate": 8.61462251465848e-06,
      "loss": 2.0014,
      "step": 2200
    },
    {
      "epoch": 0.24828670935849906,
      "grad_norm": 14.699260711669922,
      "learning_rate": 8.602337816144615e-06,
      "loss": 1.5395,
      "step": 2210
    },
    {
      "epoch": 0.24941017863161444,
      "grad_norm": 10.117761611938477,
      "learning_rate": 8.590007734020058e-06,
      "loss": 2.1292,
      "step": 2220
    },
    {
      "epoch": 0.2505336479047298,
      "grad_norm": 7.587532997131348,
      "learning_rate": 8.577632423623833e-06,
      "loss": 1.8849,
      "step": 2230
    },
    {
      "epoch": 0.25165711717784517,
      "grad_norm": 5.793702125549316,
      "learning_rate": 8.56521204086477e-06,
      "loss": 1.7817,
      "step": 2240
    },
    {
      "epoch": 0.2527805864509606,
      "grad_norm": 7.417726993560791,
      "learning_rate": 8.552746742219535e-06,
      "loss": 1.9188,
      "step": 2250
    },
    {
      "epoch": 0.2539040557240759,
      "grad_norm": 6.134685516357422,
      "learning_rate": 8.540236684730662e-06,
      "loss": 2.1267,
      "step": 2260
    },
    {
      "epoch": 0.25502752499719133,
      "grad_norm": 7.769077301025391,
      "learning_rate": 8.527682026004578e-06,
      "loss": 1.726,
      "step": 2270
    },
    {
      "epoch": 0.2561509942703067,
      "grad_norm": 8.392252922058105,
      "learning_rate": 8.515082924209607e-06,
      "loss": 1.8258,
      "step": 2280
    },
    {
      "epoch": 0.2572744635434221,
      "grad_norm": 7.6079277992248535,
      "learning_rate": 8.502439538073985e-06,
      "loss": 1.7489,
      "step": 2290
    },
    {
      "epoch": 0.25839793281653745,
      "grad_norm": 8.797737121582031,
      "learning_rate": 8.489752026883862e-06,
      "loss": 2.093,
      "step": 2300
    },
    {
      "epoch": 0.25952140208965285,
      "grad_norm": 5.908908367156982,
      "learning_rate": 8.477020550481288e-06,
      "loss": 2.0468,
      "step": 2310
    },
    {
      "epoch": 0.2606448713627682,
      "grad_norm": 17.68787384033203,
      "learning_rate": 8.464245269262208e-06,
      "loss": 1.8428,
      "step": 2320
    },
    {
      "epoch": 0.2617683406358836,
      "grad_norm": 7.359553337097168,
      "learning_rate": 8.451426344174433e-06,
      "loss": 1.5909,
      "step": 2330
    },
    {
      "epoch": 0.26289180990899896,
      "grad_norm": 7.1691670417785645,
      "learning_rate": 8.438563936715613e-06,
      "loss": 2.0305,
      "step": 2340
    },
    {
      "epoch": 0.26401527918211437,
      "grad_norm": 7.396111965179443,
      "learning_rate": 8.425658208931215e-06,
      "loss": 2.1003,
      "step": 2350
    },
    {
      "epoch": 0.2651387484552297,
      "grad_norm": 6.245526313781738,
      "learning_rate": 8.412709323412463e-06,
      "loss": 1.6424,
      "step": 2360
    },
    {
      "epoch": 0.26626221772834513,
      "grad_norm": 9.66364860534668,
      "learning_rate": 8.399717443294302e-06,
      "loss": 2.3299,
      "step": 2370
    },
    {
      "epoch": 0.26738568700146054,
      "grad_norm": 8.650711059570312,
      "learning_rate": 8.38668273225334e-06,
      "loss": 2.0106,
      "step": 2380
    },
    {
      "epoch": 0.2685091562745759,
      "grad_norm": 8.465444564819336,
      "learning_rate": 8.373605354505778e-06,
      "loss": 2.0321,
      "step": 2390
    },
    {
      "epoch": 0.2696326255476913,
      "grad_norm": 7.666931629180908,
      "learning_rate": 8.36048547480536e-06,
      "loss": 1.8821,
      "step": 2400
    },
    {
      "epoch": 0.27075609482080665,
      "grad_norm": 5.4854912757873535,
      "learning_rate": 8.347323258441277e-06,
      "loss": 1.8782,
      "step": 2410
    },
    {
      "epoch": 0.27187956409392205,
      "grad_norm": 6.883998870849609,
      "learning_rate": 8.334118871236098e-06,
      "loss": 2.0269,
      "step": 2420
    },
    {
      "epoch": 0.2730030333670374,
      "grad_norm": 8.16451644897461,
      "learning_rate": 8.320872479543673e-06,
      "loss": 1.3986,
      "step": 2430
    },
    {
      "epoch": 0.2741265026401528,
      "grad_norm": 6.733856201171875,
      "learning_rate": 8.307584250247039e-06,
      "loss": 2.0456,
      "step": 2440
    },
    {
      "epoch": 0.27524997191326817,
      "grad_norm": 5.5832929611206055,
      "learning_rate": 8.294254350756323e-06,
      "loss": 1.7024,
      "step": 2450
    },
    {
      "epoch": 0.2763734411863836,
      "grad_norm": 6.227593898773193,
      "learning_rate": 8.280882949006629e-06,
      "loss": 1.862,
      "step": 2460
    },
    {
      "epoch": 0.2774969104594989,
      "grad_norm": 13.227913856506348,
      "learning_rate": 8.267470213455916e-06,
      "loss": 2.1027,
      "step": 2470
    },
    {
      "epoch": 0.27862037973261433,
      "grad_norm": 20.39259910583496,
      "learning_rate": 8.25401631308289e-06,
      "loss": 2.3531,
      "step": 2480
    },
    {
      "epoch": 0.2797438490057297,
      "grad_norm": 13.179489135742188,
      "learning_rate": 8.24052141738486e-06,
      "loss": 1.9793,
      "step": 2490
    },
    {
      "epoch": 0.2808673182788451,
      "grad_norm": 6.982088088989258,
      "learning_rate": 8.226985696375615e-06,
      "loss": 2.1104,
      "step": 2500
    },
    {
      "epoch": 0.28199078755196044,
      "grad_norm": 8.906137466430664,
      "learning_rate": 8.213409320583274e-06,
      "loss": 2.0258,
      "step": 2510
    },
    {
      "epoch": 0.28311425682507585,
      "grad_norm": 9.489155769348145,
      "learning_rate": 8.199792461048141e-06,
      "loss": 1.9571,
      "step": 2520
    },
    {
      "epoch": 0.2842377260981912,
      "grad_norm": 8.256683349609375,
      "learning_rate": 8.186135289320548e-06,
      "loss": 2.1404,
      "step": 2530
    },
    {
      "epoch": 0.2853611953713066,
      "grad_norm": 6.077438831329346,
      "learning_rate": 8.172437977458694e-06,
      "loss": 2.1404,
      "step": 2540
    },
    {
      "epoch": 0.28648466464442196,
      "grad_norm": 7.521726131439209,
      "learning_rate": 8.158700698026484e-06,
      "loss": 1.5412,
      "step": 2550
    },
    {
      "epoch": 0.28760813391753737,
      "grad_norm": 8.949441909790039,
      "learning_rate": 8.144923624091346e-06,
      "loss": 2.0888,
      "step": 2560
    },
    {
      "epoch": 0.2887316031906527,
      "grad_norm": 7.976325988769531,
      "learning_rate": 8.131106929222054e-06,
      "loss": 2.0341,
      "step": 2570
    },
    {
      "epoch": 0.2898550724637681,
      "grad_norm": 7.006155490875244,
      "learning_rate": 8.117250787486542e-06,
      "loss": 1.669,
      "step": 2580
    },
    {
      "epoch": 0.2909785417368835,
      "grad_norm": 5.843044757843018,
      "learning_rate": 8.103355373449708e-06,
      "loss": 1.6117,
      "step": 2590
    },
    {
      "epoch": 0.2921020110099989,
      "grad_norm": 9.521520614624023,
      "learning_rate": 8.089420862171222e-06,
      "loss": 1.8214,
      "step": 2600
    },
    {
      "epoch": 0.29322548028311424,
      "grad_norm": 6.346120834350586,
      "learning_rate": 8.075447429203316e-06,
      "loss": 1.999,
      "step": 2610
    },
    {
      "epoch": 0.29434894955622964,
      "grad_norm": 10.98154354095459,
      "learning_rate": 8.061435250588564e-06,
      "loss": 1.9681,
      "step": 2620
    },
    {
      "epoch": 0.295472418829345,
      "grad_norm": 9.344758033752441,
      "learning_rate": 8.047384502857684e-06,
      "loss": 1.7466,
      "step": 2630
    },
    {
      "epoch": 0.2965958881024604,
      "grad_norm": 9.080863952636719,
      "learning_rate": 8.03329536302729e-06,
      "loss": 2.2811,
      "step": 2640
    },
    {
      "epoch": 0.29771935737557575,
      "grad_norm": 10.882134437561035,
      "learning_rate": 8.019168008597686e-06,
      "loss": 1.7684,
      "step": 2650
    },
    {
      "epoch": 0.29884282664869116,
      "grad_norm": 10.168910026550293,
      "learning_rate": 8.005002617550608e-06,
      "loss": 1.5644,
      "step": 2660
    },
    {
      "epoch": 0.2999662959218065,
      "grad_norm": 7.9981865882873535,
      "learning_rate": 7.990799368346999e-06,
      "loss": 2.0143,
      "step": 2670
    },
    {
      "epoch": 0.3010897651949219,
      "grad_norm": 6.789575099945068,
      "learning_rate": 7.976558439924748e-06,
      "loss": 1.5878,
      "step": 2680
    },
    {
      "epoch": 0.3022132344680373,
      "grad_norm": 6.3011884689331055,
      "learning_rate": 7.962280011696444e-06,
      "loss": 2.0026,
      "step": 2690
    },
    {
      "epoch": 0.3033367037411527,
      "grad_norm": 9.065674781799316,
      "learning_rate": 7.947964263547113e-06,
      "loss": 1.7679,
      "step": 2700
    },
    {
      "epoch": 0.3044601730142681,
      "grad_norm": 8.253866195678711,
      "learning_rate": 7.933611375831949e-06,
      "loss": 1.6435,
      "step": 2710
    },
    {
      "epoch": 0.30558364228738344,
      "grad_norm": 8.671612739562988,
      "learning_rate": 7.919221529374046e-06,
      "loss": 2.0302,
      "step": 2720
    },
    {
      "epoch": 0.30670711156049885,
      "grad_norm": 7.897228717803955,
      "learning_rate": 7.904794905462118e-06,
      "loss": 1.9273,
      "step": 2730
    },
    {
      "epoch": 0.3078305808336142,
      "grad_norm": 8.02452564239502,
      "learning_rate": 7.890331685848216e-06,
      "loss": 1.8999,
      "step": 2740
    },
    {
      "epoch": 0.3089540501067296,
      "grad_norm": 7.812126636505127,
      "learning_rate": 7.875832052745435e-06,
      "loss": 2.0535,
      "step": 2750
    },
    {
      "epoch": 0.31007751937984496,
      "grad_norm": 10.129742622375488,
      "learning_rate": 7.861296188825624e-06,
      "loss": 2.1119,
      "step": 2760
    },
    {
      "epoch": 0.31120098865296036,
      "grad_norm": 12.521512031555176,
      "learning_rate": 7.846724277217076e-06,
      "loss": 1.8155,
      "step": 2770
    },
    {
      "epoch": 0.3123244579260757,
      "grad_norm": 9.07133674621582,
      "learning_rate": 7.832116501502238e-06,
      "loss": 1.8706,
      "step": 2780
    },
    {
      "epoch": 0.3134479271991911,
      "grad_norm": 9.849682807922363,
      "learning_rate": 7.817473045715371e-06,
      "loss": 2.2535,
      "step": 2790
    },
    {
      "epoch": 0.3145713964723065,
      "grad_norm": 12.648999214172363,
      "learning_rate": 7.80279409434026e-06,
      "loss": 1.9967,
      "step": 2800
    },
    {
      "epoch": 0.3156948657454219,
      "grad_norm": 10.935157775878906,
      "learning_rate": 7.788079832307869e-06,
      "loss": 1.6379,
      "step": 2810
    },
    {
      "epoch": 0.31681833501853723,
      "grad_norm": 5.895432949066162,
      "learning_rate": 7.773330444994023e-06,
      "loss": 1.9967,
      "step": 2820
    },
    {
      "epoch": 0.31794180429165264,
      "grad_norm": 6.776241779327393,
      "learning_rate": 7.758546118217066e-06,
      "loss": 1.9087,
      "step": 2830
    },
    {
      "epoch": 0.319065273564768,
      "grad_norm": 9.215081214904785,
      "learning_rate": 7.743727038235524e-06,
      "loss": 1.9885,
      "step": 2840
    },
    {
      "epoch": 0.3201887428378834,
      "grad_norm": 9.124141693115234,
      "learning_rate": 7.728873391745758e-06,
      "loss": 2.1124,
      "step": 2850
    },
    {
      "epoch": 0.32131221211099875,
      "grad_norm": 6.638932228088379,
      "learning_rate": 7.713985365879607e-06,
      "loss": 1.7435,
      "step": 2860
    },
    {
      "epoch": 0.32243568138411416,
      "grad_norm": 9.445178985595703,
      "learning_rate": 7.699063148202039e-06,
      "loss": 2.0719,
      "step": 2870
    },
    {
      "epoch": 0.3235591506572295,
      "grad_norm": 9.501945495605469,
      "learning_rate": 7.68410692670878e-06,
      "loss": 2.1618,
      "step": 2880
    },
    {
      "epoch": 0.3246826199303449,
      "grad_norm": 8.552797317504883,
      "learning_rate": 7.669116889823955e-06,
      "loss": 1.6366,
      "step": 2890
    },
    {
      "epoch": 0.32580608920346027,
      "grad_norm": 11.199751853942871,
      "learning_rate": 7.654093226397696e-06,
      "loss": 2.1194,
      "step": 2900
    },
    {
      "epoch": 0.3269295584765757,
      "grad_norm": 10.334542274475098,
      "learning_rate": 7.639036125703787e-06,
      "loss": 1.7804,
      "step": 2910
    },
    {
      "epoch": 0.32805302774969103,
      "grad_norm": 17.73841667175293,
      "learning_rate": 7.623945777437261e-06,
      "loss": 1.9951,
      "step": 2920
    },
    {
      "epoch": 0.32917649702280644,
      "grad_norm": 5.5070905685424805,
      "learning_rate": 7.608822371712017e-06,
      "loss": 1.8321,
      "step": 2930
    },
    {
      "epoch": 0.3302999662959218,
      "grad_norm": 6.753676891326904,
      "learning_rate": 7.5936660990584256e-06,
      "loss": 1.7037,
      "step": 2940
    },
    {
      "epoch": 0.3314234355690372,
      "grad_norm": 6.785059452056885,
      "learning_rate": 7.578477150420929e-06,
      "loss": 2.1314,
      "step": 2950
    },
    {
      "epoch": 0.33254690484215255,
      "grad_norm": 10.67232608795166,
      "learning_rate": 7.563255717155629e-06,
      "loss": 2.2509,
      "step": 2960
    },
    {
      "epoch": 0.33367037411526795,
      "grad_norm": 14.23281478881836,
      "learning_rate": 7.548001991027885e-06,
      "loss": 2.102,
      "step": 2970
    },
    {
      "epoch": 0.3347938433883833,
      "grad_norm": 5.750830173492432,
      "learning_rate": 7.532716164209894e-06,
      "loss": 2.0966,
      "step": 2980
    },
    {
      "epoch": 0.3359173126614987,
      "grad_norm": 14.712825775146484,
      "learning_rate": 7.517398429278264e-06,
      "loss": 1.7948,
      "step": 2990
    },
    {
      "epoch": 0.33704078193461406,
      "grad_norm": 11.415657043457031,
      "learning_rate": 7.502048979211604e-06,
      "loss": 1.7599,
      "step": 3000
    },
    {
      "epoch": 0.33816425120772947,
      "grad_norm": 10.65223217010498,
      "learning_rate": 7.486668007388073e-06,
      "loss": 1.8435,
      "step": 3010
    },
    {
      "epoch": 0.3392877204808448,
      "grad_norm": 10.765087127685547,
      "learning_rate": 7.471255707582956e-06,
      "loss": 2.1048,
      "step": 3020
    },
    {
      "epoch": 0.34041118975396023,
      "grad_norm": 7.567082405090332,
      "learning_rate": 7.45581227396622e-06,
      "loss": 2.0476,
      "step": 3030
    },
    {
      "epoch": 0.3415346590270756,
      "grad_norm": 10.064901351928711,
      "learning_rate": 7.440337901100067e-06,
      "loss": 1.9231,
      "step": 3040
    },
    {
      "epoch": 0.342658128300191,
      "grad_norm": 9.274181365966797,
      "learning_rate": 7.424832783936484e-06,
      "loss": 1.8009,
      "step": 3050
    },
    {
      "epoch": 0.3437815975733064,
      "grad_norm": 6.291311264038086,
      "learning_rate": 7.409297117814786e-06,
      "loss": 1.7227,
      "step": 3060
    },
    {
      "epoch": 0.34490506684642175,
      "grad_norm": 16.31405258178711,
      "learning_rate": 7.393731098459156e-06,
      "loss": 1.8669,
      "step": 3070
    },
    {
      "epoch": 0.34602853611953716,
      "grad_norm": 8.106738090515137,
      "learning_rate": 7.378134921976176e-06,
      "loss": 2.1018,
      "step": 3080
    },
    {
      "epoch": 0.3471520053926525,
      "grad_norm": 9.99907398223877,
      "learning_rate": 7.3625087848523615e-06,
      "loss": 1.6478,
      "step": 3090
    },
    {
      "epoch": 0.3482754746657679,
      "grad_norm": 9.249089241027832,
      "learning_rate": 7.346852883951683e-06,
      "loss": 1.9349,
      "step": 3100
    },
    {
      "epoch": 0.34939894393888327,
      "grad_norm": 8.057109832763672,
      "learning_rate": 7.331167416513084e-06,
      "loss": 1.633,
      "step": 3110
    },
    {
      "epoch": 0.3505224132119987,
      "grad_norm": 7.2906670570373535,
      "learning_rate": 7.315452580148004e-06,
      "loss": 1.8357,
      "step": 3120
    },
    {
      "epoch": 0.351645882485114,
      "grad_norm": 6.465008735656738,
      "learning_rate": 7.299708572837875e-06,
      "loss": 1.9662,
      "step": 3130
    },
    {
      "epoch": 0.35276935175822943,
      "grad_norm": 8.386099815368652,
      "learning_rate": 7.283935592931642e-06,
      "loss": 1.8261,
      "step": 3140
    },
    {
      "epoch": 0.3538928210313448,
      "grad_norm": 7.294437408447266,
      "learning_rate": 7.2681338391432565e-06,
      "loss": 1.8784,
      "step": 3150
    },
    {
      "epoch": 0.3550162903044602,
      "grad_norm": 14.137358665466309,
      "learning_rate": 7.252303510549175e-06,
      "loss": 2.0412,
      "step": 3160
    },
    {
      "epoch": 0.35613975957757554,
      "grad_norm": 8.198707580566406,
      "learning_rate": 7.2364448065858435e-06,
      "loss": 2.3814,
      "step": 3170
    },
    {
      "epoch": 0.35726322885069095,
      "grad_norm": 8.946595191955566,
      "learning_rate": 7.2205579270472e-06,
      "loss": 1.6571,
      "step": 3180
    },
    {
      "epoch": 0.3583866981238063,
      "grad_norm": 28.08186149597168,
      "learning_rate": 7.204643072082148e-06,
      "loss": 1.6829,
      "step": 3190
    },
    {
      "epoch": 0.3595101673969217,
      "grad_norm": 8.483267784118652,
      "learning_rate": 7.18870044219203e-06,
      "loss": 1.9932,
      "step": 3200
    },
    {
      "epoch": 0.36063363667003706,
      "grad_norm": 9.329663276672363,
      "learning_rate": 7.172730238228114e-06,
      "loss": 1.7289,
      "step": 3210
    },
    {
      "epoch": 0.36175710594315247,
      "grad_norm": 7.967329502105713,
      "learning_rate": 7.156732661389052e-06,
      "loss": 2.0407,
      "step": 3220
    },
    {
      "epoch": 0.3628805752162678,
      "grad_norm": 7.889253616333008,
      "learning_rate": 7.140707913218352e-06,
      "loss": 1.8934,
      "step": 3230
    },
    {
      "epoch": 0.3640040444893832,
      "grad_norm": 10.91958236694336,
      "learning_rate": 7.124656195601838e-06,
      "loss": 1.8582,
      "step": 3240
    },
    {
      "epoch": 0.3651275137624986,
      "grad_norm": 7.104875087738037,
      "learning_rate": 7.108577710765101e-06,
      "loss": 1.7488,
      "step": 3250
    },
    {
      "epoch": 0.366250983035614,
      "grad_norm": 11.13193130493164,
      "learning_rate": 7.092472661270961e-06,
      "loss": 1.4617,
      "step": 3260
    },
    {
      "epoch": 0.36737445230872934,
      "grad_norm": 8.224139213562012,
      "learning_rate": 7.076341250016904e-06,
      "loss": 1.9603,
      "step": 3270
    },
    {
      "epoch": 0.36849792158184475,
      "grad_norm": 8.134989738464355,
      "learning_rate": 7.060183680232535e-06,
      "loss": 1.8991,
      "step": 3280
    },
    {
      "epoch": 0.3696213908549601,
      "grad_norm": 6.767056941986084,
      "learning_rate": 7.044000155477015e-06,
      "loss": 2.182,
      "step": 3290
    },
    {
      "epoch": 0.3707448601280755,
      "grad_norm": 7.677852153778076,
      "learning_rate": 7.027790879636491e-06,
      "loss": 1.8904,
      "step": 3300
    },
    {
      "epoch": 0.37186832940119086,
      "grad_norm": 9.751005172729492,
      "learning_rate": 7.011556056921536e-06,
      "loss": 1.7921,
      "step": 3310
    },
    {
      "epoch": 0.37299179867430626,
      "grad_norm": 7.2903733253479,
      "learning_rate": 6.99529589186457e-06,
      "loss": 1.8053,
      "step": 3320
    },
    {
      "epoch": 0.3741152679474216,
      "grad_norm": 15.224530220031738,
      "learning_rate": 6.979010589317287e-06,
      "loss": 1.8561,
      "step": 3330
    },
    {
      "epoch": 0.375238737220537,
      "grad_norm": 7.752798557281494,
      "learning_rate": 6.962700354448072e-06,
      "loss": 2.1216,
      "step": 3340
    },
    {
      "epoch": 0.3763622064936524,
      "grad_norm": 8.002140998840332,
      "learning_rate": 6.946365392739415e-06,
      "loss": 1.9211,
      "step": 3350
    },
    {
      "epoch": 0.3774856757667678,
      "grad_norm": 8.233062744140625,
      "learning_rate": 6.930005909985327e-06,
      "loss": 2.1048,
      "step": 3360
    },
    {
      "epoch": 0.37860914503988313,
      "grad_norm": 6.558511257171631,
      "learning_rate": 6.913622112288741e-06,
      "loss": 1.6947,
      "step": 3370
    },
    {
      "epoch": 0.37973261431299854,
      "grad_norm": 16.009641647338867,
      "learning_rate": 6.897214206058922e-06,
      "loss": 1.6263,
      "step": 3380
    },
    {
      "epoch": 0.38085608358611395,
      "grad_norm": 12.802122116088867,
      "learning_rate": 6.880782398008862e-06,
      "loss": 2.0053,
      "step": 3390
    },
    {
      "epoch": 0.3819795528592293,
      "grad_norm": 16.141260147094727,
      "learning_rate": 6.864326895152677e-06,
      "loss": 2.1314,
      "step": 3400
    },
    {
      "epoch": 0.3831030221323447,
      "grad_norm": 9.551617622375488,
      "learning_rate": 6.847847904803001e-06,
      "loss": 2.052,
      "step": 3410
    },
    {
      "epoch": 0.38422649140546006,
      "grad_norm": 12.148962020874023,
      "learning_rate": 6.831345634568367e-06,
      "loss": 1.6322,
      "step": 3420
    },
    {
      "epoch": 0.38534996067857546,
      "grad_norm": 18.310943603515625,
      "learning_rate": 6.8148202923506054e-06,
      "loss": 1.8776,
      "step": 3430
    },
    {
      "epoch": 0.3864734299516908,
      "grad_norm": 37.95123291015625,
      "learning_rate": 6.798272086342208e-06,
      "loss": 2.4996,
      "step": 3440
    },
    {
      "epoch": 0.3875968992248062,
      "grad_norm": 6.75761079788208,
      "learning_rate": 6.7817012250237156e-06,
      "loss": 2.1713,
      "step": 3450
    },
    {
      "epoch": 0.3887203684979216,
      "grad_norm": 8.083690643310547,
      "learning_rate": 6.765107917161093e-06,
      "loss": 2.0477,
      "step": 3460
    },
    {
      "epoch": 0.389843837771037,
      "grad_norm": 7.265686511993408,
      "learning_rate": 6.748492371803089e-06,
      "loss": 1.8823,
      "step": 3470
    },
    {
      "epoch": 0.39096730704415233,
      "grad_norm": 5.722314357757568,
      "learning_rate": 6.731854798278614e-06,
      "loss": 1.8035,
      "step": 3480
    },
    {
      "epoch": 0.39209077631726774,
      "grad_norm": 6.695064067840576,
      "learning_rate": 6.715195406194096e-06,
      "loss": 1.9254,
      "step": 3490
    },
    {
      "epoch": 0.3932142455903831,
      "grad_norm": 8.044477462768555,
      "learning_rate": 6.698514405430838e-06,
      "loss": 1.518,
      "step": 3500
    },
    {
      "epoch": 0.3943377148634985,
      "grad_norm": 18.94199562072754,
      "learning_rate": 6.681812006142381e-06,
      "loss": 1.8986,
      "step": 3510
    },
    {
      "epoch": 0.39546118413661385,
      "grad_norm": 8.445507049560547,
      "learning_rate": 6.665088418751853e-06,
      "loss": 1.6831,
      "step": 3520
    },
    {
      "epoch": 0.39658465340972926,
      "grad_norm": 9.201519966125488,
      "learning_rate": 6.6483438539493165e-06,
      "loss": 1.7364,
      "step": 3530
    },
    {
      "epoch": 0.3977081226828446,
      "grad_norm": 8.324296951293945,
      "learning_rate": 6.631578522689113e-06,
      "loss": 1.7947,
      "step": 3540
    },
    {
      "epoch": 0.39883159195596,
      "grad_norm": 7.843647480010986,
      "learning_rate": 6.614792636187213e-06,
      "loss": 1.9047,
      "step": 3550
    },
    {
      "epoch": 0.39995506122907537,
      "grad_norm": 8.156665802001953,
      "learning_rate": 6.597986405918543e-06,
      "loss": 2.0087,
      "step": 3560
    },
    {
      "epoch": 0.4010785305021908,
      "grad_norm": 10.652397155761719,
      "learning_rate": 6.581160043614335e-06,
      "loss": 2.1076,
      "step": 3570
    },
    {
      "epoch": 0.40220199977530613,
      "grad_norm": 7.781308650970459,
      "learning_rate": 6.564313761259449e-06,
      "loss": 1.7071,
      "step": 3580
    },
    {
      "epoch": 0.40332546904842154,
      "grad_norm": 8.963170051574707,
      "learning_rate": 6.547447771089701e-06,
      "loss": 1.6182,
      "step": 3590
    },
    {
      "epoch": 0.4044489383215369,
      "grad_norm": 8.064790725708008,
      "learning_rate": 6.5305622855892004e-06,
      "loss": 1.7476,
      "step": 3600
    },
    {
      "epoch": 0.4055724075946523,
      "grad_norm": 10.650609970092773,
      "learning_rate": 6.513657517487662e-06,
      "loss": 2.0304,
      "step": 3610
    },
    {
      "epoch": 0.40669587686776765,
      "grad_norm": 6.995274543762207,
      "learning_rate": 6.496733679757733e-06,
      "loss": 1.9839,
      "step": 3620
    },
    {
      "epoch": 0.40781934614088305,
      "grad_norm": 9.207695007324219,
      "learning_rate": 6.479790985612304e-06,
      "loss": 1.8969,
      "step": 3630
    },
    {
      "epoch": 0.4089428154139984,
      "grad_norm": 9.769898414611816,
      "learning_rate": 6.462829648501826e-06,
      "loss": 2.0214,
      "step": 3640
    },
    {
      "epoch": 0.4100662846871138,
      "grad_norm": 9.486366271972656,
      "learning_rate": 6.4458498821116225e-06,
      "loss": 1.6197,
      "step": 3650
    },
    {
      "epoch": 0.41118975396022917,
      "grad_norm": 9.632526397705078,
      "learning_rate": 6.428851900359196e-06,
      "loss": 2.4918,
      "step": 3660
    },
    {
      "epoch": 0.4123132232333446,
      "grad_norm": 8.451822280883789,
      "learning_rate": 6.411835917391535e-06,
      "loss": 1.4907,
      "step": 3670
    },
    {
      "epoch": 0.4134366925064599,
      "grad_norm": 8.188855171203613,
      "learning_rate": 6.3948021475824084e-06,
      "loss": 2.172,
      "step": 3680
    },
    {
      "epoch": 0.41456016177957533,
      "grad_norm": 8.076021194458008,
      "learning_rate": 6.377750805529675e-06,
      "loss": 1.8393,
      "step": 3690
    },
    {
      "epoch": 0.4156836310526907,
      "grad_norm": 13.824182510375977,
      "learning_rate": 6.360682106052573e-06,
      "loss": 2.1732,
      "step": 3700
    },
    {
      "epoch": 0.4168071003258061,
      "grad_norm": 5.781147003173828,
      "learning_rate": 6.343596264189019e-06,
      "loss": 1.767,
      "step": 3710
    },
    {
      "epoch": 0.41793056959892144,
      "grad_norm": 10.26796817779541,
      "learning_rate": 6.326493495192892e-06,
      "loss": 1.9634,
      "step": 3720
    },
    {
      "epoch": 0.41905403887203685,
      "grad_norm": 7.961363792419434,
      "learning_rate": 6.309374014531331e-06,
      "loss": 1.7066,
      "step": 3730
    },
    {
      "epoch": 0.42017750814515226,
      "grad_norm": 10.880535125732422,
      "learning_rate": 6.2922380378820056e-06,
      "loss": 2.0173,
      "step": 3740
    },
    {
      "epoch": 0.4213009774182676,
      "grad_norm": 8.523880958557129,
      "learning_rate": 6.275085781130419e-06,
      "loss": 2.0915,
      "step": 3750
    },
    {
      "epoch": 0.422424446691383,
      "grad_norm": 11.853973388671875,
      "learning_rate": 6.257917460367171e-06,
      "loss": 2.1544,
      "step": 3760
    },
    {
      "epoch": 0.42354791596449837,
      "grad_norm": 8.932334899902344,
      "learning_rate": 6.240733291885239e-06,
      "loss": 2.1008,
      "step": 3770
    },
    {
      "epoch": 0.4246713852376138,
      "grad_norm": 6.377321720123291,
      "learning_rate": 6.223533492177265e-06,
      "loss": 1.9086,
      "step": 3780
    },
    {
      "epoch": 0.4257948545107291,
      "grad_norm": 6.821984767913818,
      "learning_rate": 6.206318277932809e-06,
      "loss": 2.0541,
      "step": 3790
    },
    {
      "epoch": 0.42691832378384453,
      "grad_norm": 8.795928955078125,
      "learning_rate": 6.189087866035638e-06,
      "loss": 2.161,
      "step": 3800
    },
    {
      "epoch": 0.4280417930569599,
      "grad_norm": 10.15861701965332,
      "learning_rate": 6.171842473560979e-06,
      "loss": 1.7522,
      "step": 3810
    },
    {
      "epoch": 0.4291652623300753,
      "grad_norm": 6.692728519439697,
      "learning_rate": 6.154582317772793e-06,
      "loss": 1.5844,
      "step": 3820
    },
    {
      "epoch": 0.43028873160319064,
      "grad_norm": 6.670084476470947,
      "learning_rate": 6.137307616121031e-06,
      "loss": 1.9746,
      "step": 3830
    },
    {
      "epoch": 0.43141220087630605,
      "grad_norm": 10.091155052185059,
      "learning_rate": 6.120018586238902e-06,
      "loss": 1.6963,
      "step": 3840
    },
    {
      "epoch": 0.4325356701494214,
      "grad_norm": 9.869091033935547,
      "learning_rate": 6.1027154459401295e-06,
      "loss": 1.6283,
      "step": 3850
    },
    {
      "epoch": 0.4336591394225368,
      "grad_norm": 6.660030841827393,
      "learning_rate": 6.085398413216196e-06,
      "loss": 1.9824,
      "step": 3860
    },
    {
      "epoch": 0.43478260869565216,
      "grad_norm": 5.791511535644531,
      "learning_rate": 6.068067706233617e-06,
      "loss": 1.8773,
      "step": 3870
    },
    {
      "epoch": 0.43590607796876757,
      "grad_norm": 12.734137535095215,
      "learning_rate": 6.050723543331175e-06,
      "loss": 1.9296,
      "step": 3880
    },
    {
      "epoch": 0.4370295472418829,
      "grad_norm": 7.437817096710205,
      "learning_rate": 6.033366143017176e-06,
      "loss": 1.3101,
      "step": 3890
    },
    {
      "epoch": 0.43815301651499833,
      "grad_norm": 7.9752607345581055,
      "learning_rate": 6.0159957239666996e-06,
      "loss": 1.8811,
      "step": 3900
    },
    {
      "epoch": 0.4392764857881137,
      "grad_norm": 8.213449478149414,
      "learning_rate": 5.998612505018833e-06,
      "loss": 1.5689,
      "step": 3910
    },
    {
      "epoch": 0.4403999550612291,
      "grad_norm": 9.82950496673584,
      "learning_rate": 5.98121670517393e-06,
      "loss": 1.5442,
      "step": 3920
    },
    {
      "epoch": 0.44152342433434444,
      "grad_norm": 17.555356979370117,
      "learning_rate": 5.9638085435908365e-06,
      "loss": 1.7318,
      "step": 3930
    },
    {
      "epoch": 0.44264689360745985,
      "grad_norm": 6.812912464141846,
      "learning_rate": 5.9463882395841425e-06,
      "loss": 1.8186,
      "step": 3940
    },
    {
      "epoch": 0.4437703628805752,
      "grad_norm": 7.775144577026367,
      "learning_rate": 5.928956012621404e-06,
      "loss": 1.9119,
      "step": 3950
    },
    {
      "epoch": 0.4448938321536906,
      "grad_norm": 7.785953521728516,
      "learning_rate": 5.911512082320397e-06,
      "loss": 1.7188,
      "step": 3960
    },
    {
      "epoch": 0.44601730142680596,
      "grad_norm": 7.750124931335449,
      "learning_rate": 5.894056668446332e-06,
      "loss": 1.9276,
      "step": 3970
    },
    {
      "epoch": 0.44714077069992136,
      "grad_norm": 7.468532085418701,
      "learning_rate": 5.8765899909090985e-06,
      "loss": 1.752,
      "step": 3980
    },
    {
      "epoch": 0.4482642399730367,
      "grad_norm": 16.802291870117188,
      "learning_rate": 5.8591122697604915e-06,
      "loss": 2.0655,
      "step": 3990
    },
    {
      "epoch": 0.4493877092461521,
      "grad_norm": 18.402984619140625,
      "learning_rate": 5.841623725191431e-06,
      "loss": 1.9931,
      "step": 4000
    },
    {
      "epoch": 0.4505111785192675,
      "grad_norm": 8.427983283996582,
      "learning_rate": 5.824124577529202e-06,
      "loss": 1.9162,
      "step": 4010
    },
    {
      "epoch": 0.4516346477923829,
      "grad_norm": 6.90464448928833,
      "learning_rate": 5.806615047234666e-06,
      "loss": 1.9258,
      "step": 4020
    },
    {
      "epoch": 0.45275811706549823,
      "grad_norm": 8.092647552490234,
      "learning_rate": 5.7890953548994915e-06,
      "loss": 1.822,
      "step": 4030
    },
    {
      "epoch": 0.45388158633861364,
      "grad_norm": 10.170499801635742,
      "learning_rate": 5.771565721243371e-06,
      "loss": 1.6511,
      "step": 4040
    },
    {
      "epoch": 0.455005055611729,
      "grad_norm": 10.158903121948242,
      "learning_rate": 5.754026367111241e-06,
      "loss": 1.814,
      "step": 4050
    },
    {
      "epoch": 0.4561285248848444,
      "grad_norm": 10.189460754394531,
      "learning_rate": 5.736477513470502e-06,
      "loss": 2.115,
      "step": 4060
    },
    {
      "epoch": 0.4572519941579598,
      "grad_norm": 9.136141777038574,
      "learning_rate": 5.718919381408231e-06,
      "loss": 1.5844,
      "step": 4070
    },
    {
      "epoch": 0.45837546343107516,
      "grad_norm": 10.047242164611816,
      "learning_rate": 5.701352192128403e-06,
      "loss": 2.2438,
      "step": 4080
    },
    {
      "epoch": 0.45949893270419057,
      "grad_norm": 10.52385425567627,
      "learning_rate": 5.68377616694909e-06,
      "loss": 1.8765,
      "step": 4090
    },
    {
      "epoch": 0.4606224019773059,
      "grad_norm": 8.250333786010742,
      "learning_rate": 5.666191527299691e-06,
      "loss": 1.9864,
      "step": 4100
    },
    {
      "epoch": 0.4617458712504213,
      "grad_norm": 8.421916007995605,
      "learning_rate": 5.6485984947181275e-06,
      "loss": 1.8474,
      "step": 4110
    },
    {
      "epoch": 0.4628693405235367,
      "grad_norm": 8.07811164855957,
      "learning_rate": 5.63099729084806e-06,
      "loss": 1.7342,
      "step": 4120
    },
    {
      "epoch": 0.4639928097966521,
      "grad_norm": 9.303871154785156,
      "learning_rate": 5.613388137436097e-06,
      "loss": 1.719,
      "step": 4130
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 4.78665018081665,
      "learning_rate": 5.595771256328994e-06,
      "loss": 1.8736,
      "step": 4140
    },
    {
      "epoch": 0.46623974834288284,
      "grad_norm": 6.697278022766113,
      "learning_rate": 5.578146869470866e-06,
      "loss": 2.1591,
      "step": 4150
    },
    {
      "epoch": 0.4673632176159982,
      "grad_norm": 9.344968795776367,
      "learning_rate": 5.560515198900385e-06,
      "loss": 2.0791,
      "step": 4160
    },
    {
      "epoch": 0.4684866868891136,
      "grad_norm": 12.15528678894043,
      "learning_rate": 5.542876466747988e-06,
      "loss": 1.6281,
      "step": 4170
    },
    {
      "epoch": 0.46961015616222895,
      "grad_norm": 18.717723846435547,
      "learning_rate": 5.525230895233081e-06,
      "loss": 2.4076,
      "step": 4180
    },
    {
      "epoch": 0.47073362543534436,
      "grad_norm": 16.913766860961914,
      "learning_rate": 5.507578706661223e-06,
      "loss": 2.1452,
      "step": 4190
    },
    {
      "epoch": 0.4718570947084597,
      "grad_norm": 10.72907543182373,
      "learning_rate": 5.48992012342135e-06,
      "loss": 2.169,
      "step": 4200
    },
    {
      "epoch": 0.4729805639815751,
      "grad_norm": 8.106353759765625,
      "learning_rate": 5.47225536798295e-06,
      "loss": 1.8055,
      "step": 4210
    },
    {
      "epoch": 0.47410403325469047,
      "grad_norm": 9.213134765625,
      "learning_rate": 5.454584662893283e-06,
      "loss": 2.0662,
      "step": 4220
    },
    {
      "epoch": 0.4752275025278059,
      "grad_norm": 8.603763580322266,
      "learning_rate": 5.436908230774549e-06,
      "loss": 1.5738,
      "step": 4230
    },
    {
      "epoch": 0.47635097180092123,
      "grad_norm": 9.335543632507324,
      "learning_rate": 5.419226294321114e-06,
      "loss": 2.029,
      "step": 4240
    },
    {
      "epoch": 0.47747444107403664,
      "grad_norm": 9.534547805786133,
      "learning_rate": 5.4015390762966815e-06,
      "loss": 2.0809,
      "step": 4250
    },
    {
      "epoch": 0.478597910347152,
      "grad_norm": 8.2122220993042,
      "learning_rate": 5.383846799531494e-06,
      "loss": 1.5798,
      "step": 4260
    },
    {
      "epoch": 0.4797213796202674,
      "grad_norm": 7.608659744262695,
      "learning_rate": 5.366149686919533e-06,
      "loss": 1.6224,
      "step": 4270
    },
    {
      "epoch": 0.48084484889338275,
      "grad_norm": 7.772457122802734,
      "learning_rate": 5.348447961415693e-06,
      "loss": 1.7911,
      "step": 4280
    },
    {
      "epoch": 0.48196831816649816,
      "grad_norm": 9.730652809143066,
      "learning_rate": 5.330741846032995e-06,
      "loss": 1.6003,
      "step": 4290
    },
    {
      "epoch": 0.4830917874396135,
      "grad_norm": 7.918702125549316,
      "learning_rate": 5.313031563839755e-06,
      "loss": 1.7113,
      "step": 4300
    },
    {
      "epoch": 0.4842152567127289,
      "grad_norm": 15.895320892333984,
      "learning_rate": 5.295317337956794e-06,
      "loss": 2.1918,
      "step": 4310
    },
    {
      "epoch": 0.48533872598584427,
      "grad_norm": 7.766380310058594,
      "learning_rate": 5.277599391554607e-06,
      "loss": 1.5355,
      "step": 4320
    },
    {
      "epoch": 0.4864621952589597,
      "grad_norm": 10.381396293640137,
      "learning_rate": 5.259877947850567e-06,
      "loss": 1.769,
      "step": 4330
    },
    {
      "epoch": 0.487585664532075,
      "grad_norm": 7.485537052154541,
      "learning_rate": 5.24215323010611e-06,
      "loss": 1.7659,
      "step": 4340
    },
    {
      "epoch": 0.48870913380519043,
      "grad_norm": 6.5303473472595215,
      "learning_rate": 5.224425461623912e-06,
      "loss": 1.9,
      "step": 4350
    },
    {
      "epoch": 0.4898326030783058,
      "grad_norm": 5.803108215332031,
      "learning_rate": 5.206694865745093e-06,
      "loss": 1.4208,
      "step": 4360
    },
    {
      "epoch": 0.4909560723514212,
      "grad_norm": 14.282977104187012,
      "learning_rate": 5.188961665846385e-06,
      "loss": 2.242,
      "step": 4370
    },
    {
      "epoch": 0.49207954162453654,
      "grad_norm": 11.287910461425781,
      "learning_rate": 5.171226085337328e-06,
      "loss": 1.8076,
      "step": 4380
    },
    {
      "epoch": 0.49320301089765195,
      "grad_norm": 6.206213474273682,
      "learning_rate": 5.1534883476574586e-06,
      "loss": 1.5795,
      "step": 4390
    },
    {
      "epoch": 0.49432648017076736,
      "grad_norm": 8.111031532287598,
      "learning_rate": 5.135748676273485e-06,
      "loss": 2.0684,
      "step": 4400
    },
    {
      "epoch": 0.4954499494438827,
      "grad_norm": 18.862884521484375,
      "learning_rate": 5.1180072946764815e-06,
      "loss": 1.979,
      "step": 4410
    },
    {
      "epoch": 0.4965734187169981,
      "grad_norm": 8.50385570526123,
      "learning_rate": 5.100264426379064e-06,
      "loss": 1.8708,
      "step": 4420
    },
    {
      "epoch": 0.49769688799011347,
      "grad_norm": 8.254416465759277,
      "learning_rate": 5.082520294912581e-06,
      "loss": 2.0915,
      "step": 4430
    },
    {
      "epoch": 0.4988203572632289,
      "grad_norm": 9.258947372436523,
      "learning_rate": 5.064775123824293e-06,
      "loss": 1.9013,
      "step": 4440
    },
    {
      "epoch": 0.4999438265363442,
      "grad_norm": 8.39799976348877,
      "learning_rate": 5.047029136674563e-06,
      "loss": 2.1107,
      "step": 4450
    },
    {
      "epoch": 0.5010672958094596,
      "grad_norm": 7.625226974487305,
      "learning_rate": 5.0292825570340274e-06,
      "loss": 2.0512,
      "step": 4460
    },
    {
      "epoch": 0.502190765082575,
      "grad_norm": 6.391541481018066,
      "learning_rate": 5.011535608480791e-06,
      "loss": 1.8023,
      "step": 4470
    },
    {
      "epoch": 0.5033142343556903,
      "grad_norm": 6.920843601226807,
      "learning_rate": 4.993788514597608e-06,
      "loss": 1.9198,
      "step": 4480
    },
    {
      "epoch": 0.5044377036288058,
      "grad_norm": 8.197586059570312,
      "learning_rate": 4.976041498969062e-06,
      "loss": 2.0375,
      "step": 4490
    },
    {
      "epoch": 0.5055611729019212,
      "grad_norm": 7.422460556030273,
      "learning_rate": 4.958294785178749e-06,
      "loss": 1.6691,
      "step": 4500
    },
    {
      "epoch": 0.5066846421750365,
      "grad_norm": 10.601027488708496,
      "learning_rate": 4.940548596806466e-06,
      "loss": 1.902,
      "step": 4510
    },
    {
      "epoch": 0.5078081114481519,
      "grad_norm": 10.312538146972656,
      "learning_rate": 4.922803157425386e-06,
      "loss": 2.0726,
      "step": 4520
    },
    {
      "epoch": 0.5089315807212673,
      "grad_norm": 30.765233993530273,
      "learning_rate": 4.905058690599248e-06,
      "loss": 1.9091,
      "step": 4530
    },
    {
      "epoch": 0.5100550499943827,
      "grad_norm": 20.178707122802734,
      "learning_rate": 4.887315419879541e-06,
      "loss": 1.6849,
      "step": 4540
    },
    {
      "epoch": 0.511178519267498,
      "grad_norm": 12.487902641296387,
      "learning_rate": 4.86957356880268e-06,
      "loss": 1.8108,
      "step": 4550
    },
    {
      "epoch": 0.5123019885406134,
      "grad_norm": 13.195343971252441,
      "learning_rate": 4.8518333608872015e-06,
      "loss": 1.8501,
      "step": 4560
    },
    {
      "epoch": 0.5134254578137288,
      "grad_norm": 11.381284713745117,
      "learning_rate": 4.834095019630935e-06,
      "loss": 1.8619,
      "step": 4570
    },
    {
      "epoch": 0.5145489270868442,
      "grad_norm": 10.673223495483398,
      "learning_rate": 4.816358768508192e-06,
      "loss": 1.7491,
      "step": 4580
    },
    {
      "epoch": 0.5156723963599595,
      "grad_norm": 10.21512222290039,
      "learning_rate": 4.798624830966958e-06,
      "loss": 1.5905,
      "step": 4590
    },
    {
      "epoch": 0.5167958656330749,
      "grad_norm": 13.72511100769043,
      "learning_rate": 4.7808934304260655e-06,
      "loss": 1.9607,
      "step": 4600
    },
    {
      "epoch": 0.5179193349061904,
      "grad_norm": 8.048547744750977,
      "learning_rate": 4.76316479027239e-06,
      "loss": 1.8148,
      "step": 4610
    },
    {
      "epoch": 0.5190428041793057,
      "grad_norm": 7.716550350189209,
      "learning_rate": 4.745439133858027e-06,
      "loss": 1.7132,
      "step": 4620
    },
    {
      "epoch": 0.5201662734524211,
      "grad_norm": 11.912676811218262,
      "learning_rate": 4.727716684497481e-06,
      "loss": 1.7447,
      "step": 4630
    },
    {
      "epoch": 0.5212897427255364,
      "grad_norm": 9.27993392944336,
      "learning_rate": 4.709997665464855e-06,
      "loss": 1.9093,
      "step": 4640
    },
    {
      "epoch": 0.5224132119986519,
      "grad_norm": 12.752988815307617,
      "learning_rate": 4.692282299991035e-06,
      "loss": 2.0905,
      "step": 4650
    },
    {
      "epoch": 0.5235366812717672,
      "grad_norm": 7.976121425628662,
      "learning_rate": 4.674570811260879e-06,
      "loss": 2.0267,
      "step": 4660
    },
    {
      "epoch": 0.5246601505448826,
      "grad_norm": 10.04601001739502,
      "learning_rate": 4.656863422410402e-06,
      "loss": 1.9022,
      "step": 4670
    },
    {
      "epoch": 0.5257836198179979,
      "grad_norm": 8.155354499816895,
      "learning_rate": 4.639160356523966e-06,
      "loss": 1.8298,
      "step": 4680
    },
    {
      "epoch": 0.5269070890911134,
      "grad_norm": 12.09203052520752,
      "learning_rate": 4.621461836631479e-06,
      "loss": 1.5363,
      "step": 4690
    },
    {
      "epoch": 0.5280305583642287,
      "grad_norm": 9.690099716186523,
      "learning_rate": 4.603768085705566e-06,
      "loss": 1.687,
      "step": 4700
    },
    {
      "epoch": 0.5291540276373441,
      "grad_norm": 8.330496788024902,
      "learning_rate": 4.586079326658776e-06,
      "loss": 1.6072,
      "step": 4710
    },
    {
      "epoch": 0.5302774969104594,
      "grad_norm": 12.188657760620117,
      "learning_rate": 4.568395782340771e-06,
      "loss": 1.9348,
      "step": 4720
    },
    {
      "epoch": 0.5314009661835749,
      "grad_norm": 7.701380252838135,
      "learning_rate": 4.55071767553551e-06,
      "loss": 2.0864,
      "step": 4730
    },
    {
      "epoch": 0.5325244354566903,
      "grad_norm": 6.958229064941406,
      "learning_rate": 4.533045228958454e-06,
      "loss": 1.981,
      "step": 4740
    },
    {
      "epoch": 0.5336479047298056,
      "grad_norm": 13.307482719421387,
      "learning_rate": 4.515378665253748e-06,
      "loss": 2.2323,
      "step": 4750
    },
    {
      "epoch": 0.5347713740029211,
      "grad_norm": 7.84748649597168,
      "learning_rate": 4.497718206991428e-06,
      "loss": 1.799,
      "step": 4760
    },
    {
      "epoch": 0.5358948432760364,
      "grad_norm": 6.433814525604248,
      "learning_rate": 4.4800640766646085e-06,
      "loss": 2.0866,
      "step": 4770
    },
    {
      "epoch": 0.5370183125491518,
      "grad_norm": 8.38242244720459,
      "learning_rate": 4.462416496686682e-06,
      "loss": 1.9808,
      "step": 4780
    },
    {
      "epoch": 0.5381417818222671,
      "grad_norm": 9.558723449707031,
      "learning_rate": 4.444775689388522e-06,
      "loss": 1.3976,
      "step": 4790
    },
    {
      "epoch": 0.5392652510953826,
      "grad_norm": 7.752072811126709,
      "learning_rate": 4.427141877015669e-06,
      "loss": 2.054,
      "step": 4800
    },
    {
      "epoch": 0.5403887203684979,
      "grad_norm": 7.718641757965088,
      "learning_rate": 4.409515281725544e-06,
      "loss": 1.6918,
      "step": 4810
    },
    {
      "epoch": 0.5415121896416133,
      "grad_norm": 9.853611946105957,
      "learning_rate": 4.391896125584645e-06,
      "loss": 1.726,
      "step": 4820
    },
    {
      "epoch": 0.5426356589147286,
      "grad_norm": 12.629629135131836,
      "learning_rate": 4.374284630565745e-06,
      "loss": 1.9534,
      "step": 4830
    },
    {
      "epoch": 0.5437591281878441,
      "grad_norm": 8.272645950317383,
      "learning_rate": 4.356681018545106e-06,
      "loss": 1.9812,
      "step": 4840
    },
    {
      "epoch": 0.5448825974609595,
      "grad_norm": 9.705422401428223,
      "learning_rate": 4.33908551129967e-06,
      "loss": 2.2921,
      "step": 4850
    },
    {
      "epoch": 0.5460060667340748,
      "grad_norm": 14.57640266418457,
      "learning_rate": 4.321498330504273e-06,
      "loss": 2.013,
      "step": 4860
    },
    {
      "epoch": 0.5471295360071902,
      "grad_norm": 11.775333404541016,
      "learning_rate": 4.303919697728857e-06,
      "loss": 1.887,
      "step": 4870
    },
    {
      "epoch": 0.5482530052803056,
      "grad_norm": 10.362658500671387,
      "learning_rate": 4.286349834435664e-06,
      "loss": 1.5205,
      "step": 4880
    },
    {
      "epoch": 0.549376474553421,
      "grad_norm": 15.171252250671387,
      "learning_rate": 4.2687889619764644e-06,
      "loss": 2.1238,
      "step": 4890
    },
    {
      "epoch": 0.5504999438265363,
      "grad_norm": 7.003702640533447,
      "learning_rate": 4.2512373015897515e-06,
      "loss": 1.8496,
      "step": 4900
    },
    {
      "epoch": 0.5516234130996517,
      "grad_norm": 9.278204917907715,
      "learning_rate": 4.233695074397962e-06,
      "loss": 1.6621,
      "step": 4910
    },
    {
      "epoch": 0.5527468823727671,
      "grad_norm": 10.894073486328125,
      "learning_rate": 4.216162501404694e-06,
      "loss": 1.7114,
      "step": 4920
    },
    {
      "epoch": 0.5538703516458825,
      "grad_norm": 7.614492893218994,
      "learning_rate": 4.198639803491915e-06,
      "loss": 1.5499,
      "step": 4930
    },
    {
      "epoch": 0.5549938209189978,
      "grad_norm": 6.3899664878845215,
      "learning_rate": 4.181127201417184e-06,
      "loss": 1.7679,
      "step": 4940
    },
    {
      "epoch": 0.5561172901921132,
      "grad_norm": 18.433155059814453,
      "learning_rate": 4.163624915810867e-06,
      "loss": 2.0807,
      "step": 4950
    },
    {
      "epoch": 0.5572407594652287,
      "grad_norm": 7.375189781188965,
      "learning_rate": 4.146133167173359e-06,
      "loss": 1.7648,
      "step": 4960
    },
    {
      "epoch": 0.558364228738344,
      "grad_norm": 6.868760585784912,
      "learning_rate": 4.128652175872312e-06,
      "loss": 1.9369,
      "step": 4970
    },
    {
      "epoch": 0.5594876980114594,
      "grad_norm": 12.978931427001953,
      "learning_rate": 4.111182162139844e-06,
      "loss": 2.1978,
      "step": 4980
    },
    {
      "epoch": 0.5606111672845747,
      "grad_norm": 10.742244720458984,
      "learning_rate": 4.09372334606978e-06,
      "loss": 1.606,
      "step": 4990
    },
    {
      "epoch": 0.5617346365576902,
      "grad_norm": 6.518197536468506,
      "learning_rate": 4.076275947614873e-06,
      "loss": 1.6501,
      "step": 5000
    },
    {
      "epoch": 0.5628581058308055,
      "grad_norm": 10.24138069152832,
      "learning_rate": 4.058840186584024e-06,
      "loss": 1.7418,
      "step": 5010
    },
    {
      "epoch": 0.5639815751039209,
      "grad_norm": 7.2170538902282715,
      "learning_rate": 4.041416282639535e-06,
      "loss": 2.1448,
      "step": 5020
    },
    {
      "epoch": 0.5651050443770362,
      "grad_norm": 12.366959571838379,
      "learning_rate": 4.0240044552943165e-06,
      "loss": 1.8929,
      "step": 5030
    },
    {
      "epoch": 0.5662285136501517,
      "grad_norm": 8.129193305969238,
      "learning_rate": 4.006604923909137e-06,
      "loss": 1.3658,
      "step": 5040
    },
    {
      "epoch": 0.567351982923267,
      "grad_norm": 8.283371925354004,
      "learning_rate": 3.989217907689859e-06,
      "loss": 2.0559,
      "step": 5050
    },
    {
      "epoch": 0.5684754521963824,
      "grad_norm": 7.176880836486816,
      "learning_rate": 3.971843625684669e-06,
      "loss": 1.6001,
      "step": 5060
    },
    {
      "epoch": 0.5695989214694978,
      "grad_norm": 13.860504150390625,
      "learning_rate": 3.954482296781329e-06,
      "loss": 1.7944,
      "step": 5070
    },
    {
      "epoch": 0.5707223907426132,
      "grad_norm": 7.034293174743652,
      "learning_rate": 3.937134139704406e-06,
      "loss": 2.0121,
      "step": 5080
    },
    {
      "epoch": 0.5718458600157286,
      "grad_norm": 11.205349922180176,
      "learning_rate": 3.919799373012528e-06,
      "loss": 1.8681,
      "step": 5090
    },
    {
      "epoch": 0.5729693292888439,
      "grad_norm": 9.569100379943848,
      "learning_rate": 3.902478215095627e-06,
      "loss": 1.6758,
      "step": 5100
    },
    {
      "epoch": 0.5740927985619594,
      "grad_norm": 15.519506454467773,
      "learning_rate": 3.885170884172182e-06,
      "loss": 1.7086,
      "step": 5110
    },
    {
      "epoch": 0.5752162678350747,
      "grad_norm": 13.7012939453125,
      "learning_rate": 3.867877598286479e-06,
      "loss": 1.6274,
      "step": 5120
    },
    {
      "epoch": 0.5763397371081901,
      "grad_norm": 12.7806978225708,
      "learning_rate": 3.850598575305855e-06,
      "loss": 1.9581,
      "step": 5130
    },
    {
      "epoch": 0.5774632063813054,
      "grad_norm": 9.113662719726562,
      "learning_rate": 3.833334032917958e-06,
      "loss": 1.9203,
      "step": 5140
    },
    {
      "epoch": 0.5785866756544209,
      "grad_norm": 8.299141883850098,
      "learning_rate": 3.816084188628009e-06,
      "loss": 2.0286,
      "step": 5150
    },
    {
      "epoch": 0.5797101449275363,
      "grad_norm": 8.359357833862305,
      "learning_rate": 3.798849259756052e-06,
      "loss": 2.1486,
      "step": 5160
    },
    {
      "epoch": 0.5808336142006516,
      "grad_norm": 7.695976257324219,
      "learning_rate": 3.7816294634342227e-06,
      "loss": 2.4434,
      "step": 5170
    },
    {
      "epoch": 0.581957083473767,
      "grad_norm": 10.767753601074219,
      "learning_rate": 3.764425016604012e-06,
      "loss": 1.6328,
      "step": 5180
    },
    {
      "epoch": 0.5830805527468824,
      "grad_norm": 9.680066108703613,
      "learning_rate": 3.747236136013527e-06,
      "loss": 1.9179,
      "step": 5190
    },
    {
      "epoch": 0.5842040220199978,
      "grad_norm": 8.068496704101562,
      "learning_rate": 3.7300630382147733e-06,
      "loss": 1.9194,
      "step": 5200
    },
    {
      "epoch": 0.5853274912931131,
      "grad_norm": 18.498018264770508,
      "learning_rate": 3.7129059395609134e-06,
      "loss": 2.0961,
      "step": 5210
    },
    {
      "epoch": 0.5864509605662285,
      "grad_norm": 11.187835693359375,
      "learning_rate": 3.6957650562035485e-06,
      "loss": 2.0928,
      "step": 5220
    },
    {
      "epoch": 0.5875744298393439,
      "grad_norm": 25.072301864624023,
      "learning_rate": 3.678640604089995e-06,
      "loss": 2.1834,
      "step": 5230
    },
    {
      "epoch": 0.5886978991124593,
      "grad_norm": 10.141414642333984,
      "learning_rate": 3.6615327989605555e-06,
      "loss": 1.7962,
      "step": 5240
    },
    {
      "epoch": 0.5898213683855746,
      "grad_norm": 14.895896911621094,
      "learning_rate": 3.6444418563458173e-06,
      "loss": 2.0529,
      "step": 5250
    },
    {
      "epoch": 0.59094483765869,
      "grad_norm": 7.430212497711182,
      "learning_rate": 3.6273679915639205e-06,
      "loss": 1.6193,
      "step": 5260
    },
    {
      "epoch": 0.5920683069318055,
      "grad_norm": 8.409953117370605,
      "learning_rate": 3.6103114197178536e-06,
      "loss": 1.9545,
      "step": 5270
    },
    {
      "epoch": 0.5931917762049208,
      "grad_norm": 7.761233329772949,
      "learning_rate": 3.5932723556927452e-06,
      "loss": 1.7716,
      "step": 5280
    },
    {
      "epoch": 0.5943152454780362,
      "grad_norm": 14.42812442779541,
      "learning_rate": 3.576251014153147e-06,
      "loss": 2.0194,
      "step": 5290
    },
    {
      "epoch": 0.5954387147511515,
      "grad_norm": 9.293947219848633,
      "learning_rate": 3.5592476095403473e-06,
      "loss": 2.0453,
      "step": 5300
    },
    {
      "epoch": 0.596562184024267,
      "grad_norm": 16.3109073638916,
      "learning_rate": 3.5422623560696466e-06,
      "loss": 2.0757,
      "step": 5310
    },
    {
      "epoch": 0.5976856532973823,
      "grad_norm": 16.214948654174805,
      "learning_rate": 3.525295467727675e-06,
      "loss": 2.0401,
      "step": 5320
    },
    {
      "epoch": 0.5988091225704977,
      "grad_norm": 7.810332775115967,
      "learning_rate": 3.508347158269695e-06,
      "loss": 1.5491,
      "step": 5330
    },
    {
      "epoch": 0.599932591843613,
      "grad_norm": 8.666951179504395,
      "learning_rate": 3.4914176412169e-06,
      "loss": 1.6067,
      "step": 5340
    },
    {
      "epoch": 0.6010560611167285,
      "grad_norm": 11.583565711975098,
      "learning_rate": 3.4745071298537345e-06,
      "loss": 1.7898,
      "step": 5350
    },
    {
      "epoch": 0.6021795303898438,
      "grad_norm": 7.855417728424072,
      "learning_rate": 3.4576158372251976e-06,
      "loss": 2.035,
      "step": 5360
    },
    {
      "epoch": 0.6033029996629592,
      "grad_norm": 10.191609382629395,
      "learning_rate": 3.440743976134166e-06,
      "loss": 2.1804,
      "step": 5370
    },
    {
      "epoch": 0.6044264689360745,
      "grad_norm": 11.453890800476074,
      "learning_rate": 3.423891759138711e-06,
      "loss": 1.8837,
      "step": 5380
    },
    {
      "epoch": 0.60554993820919,
      "grad_norm": 7.772622108459473,
      "learning_rate": 3.4070593985494184e-06,
      "loss": 1.8562,
      "step": 5390
    },
    {
      "epoch": 0.6066734074823054,
      "grad_norm": 13.851526260375977,
      "learning_rate": 3.390247106426718e-06,
      "loss": 2.0476,
      "step": 5400
    },
    {
      "epoch": 0.6077968767554207,
      "grad_norm": 10.15028190612793,
      "learning_rate": 3.373455094578206e-06,
      "loss": 1.8673,
      "step": 5410
    },
    {
      "epoch": 0.6089203460285362,
      "grad_norm": 9.956013679504395,
      "learning_rate": 3.356683574555982e-06,
      "loss": 1.6395,
      "step": 5420
    },
    {
      "epoch": 0.6100438153016515,
      "grad_norm": 8.756665229797363,
      "learning_rate": 3.339932757653984e-06,
      "loss": 1.5184,
      "step": 5430
    },
    {
      "epoch": 0.6111672845747669,
      "grad_norm": 6.962076663970947,
      "learning_rate": 3.3232028549053217e-06,
      "loss": 1.8063,
      "step": 5440
    },
    {
      "epoch": 0.6122907538478822,
      "grad_norm": 11.561314582824707,
      "learning_rate": 3.3064940770796165e-06,
      "loss": 1.9331,
      "step": 5450
    },
    {
      "epoch": 0.6134142231209977,
      "grad_norm": 8.824825286865234,
      "learning_rate": 3.2898066346803614e-06,
      "loss": 1.4726,
      "step": 5460
    },
    {
      "epoch": 0.614537692394113,
      "grad_norm": 12.689447402954102,
      "learning_rate": 3.273140737942245e-06,
      "loss": 1.9012,
      "step": 5470
    },
    {
      "epoch": 0.6156611616672284,
      "grad_norm": 13.173080444335938,
      "learning_rate": 3.256496596828524e-06,
      "loss": 2.0893,
      "step": 5480
    },
    {
      "epoch": 0.6167846309403437,
      "grad_norm": 9.721192359924316,
      "learning_rate": 3.239874421028367e-06,
      "loss": 1.806,
      "step": 5490
    },
    {
      "epoch": 0.6179081002134592,
      "grad_norm": 7.967605113983154,
      "learning_rate": 3.223274419954211e-06,
      "loss": 1.7831,
      "step": 5500
    },
    {
      "epoch": 0.6190315694865746,
      "grad_norm": 8.090415000915527,
      "learning_rate": 3.2066968027391377e-06,
      "loss": 1.7438,
      "step": 5510
    },
    {
      "epoch": 0.6201550387596899,
      "grad_norm": 9.343332290649414,
      "learning_rate": 3.190141778234216e-06,
      "loss": 1.5742,
      "step": 5520
    },
    {
      "epoch": 0.6212785080328053,
      "grad_norm": 9.38829517364502,
      "learning_rate": 3.173609555005894e-06,
      "loss": 1.8115,
      "step": 5530
    },
    {
      "epoch": 0.6224019773059207,
      "grad_norm": 14.898882865905762,
      "learning_rate": 3.157100341333356e-06,
      "loss": 2.171,
      "step": 5540
    },
    {
      "epoch": 0.6235254465790361,
      "grad_norm": 8.863072395324707,
      "learning_rate": 3.140614345205899e-06,
      "loss": 1.8185,
      "step": 5550
    },
    {
      "epoch": 0.6246489158521514,
      "grad_norm": 11.773736000061035,
      "learning_rate": 3.1241517743203274e-06,
      "loss": 1.6873,
      "step": 5560
    },
    {
      "epoch": 0.6257723851252668,
      "grad_norm": 9.489130973815918,
      "learning_rate": 3.1077128360783136e-06,
      "loss": 1.8955,
      "step": 5570
    },
    {
      "epoch": 0.6268958543983822,
      "grad_norm": 8.254190444946289,
      "learning_rate": 3.0912977375838082e-06,
      "loss": 1.9289,
      "step": 5580
    },
    {
      "epoch": 0.6280193236714976,
      "grad_norm": 11.868034362792969,
      "learning_rate": 3.0749066856404103e-06,
      "loss": 1.9416,
      "step": 5590
    },
    {
      "epoch": 0.629142792944613,
      "grad_norm": 8.59692096710205,
      "learning_rate": 3.0585398867487747e-06,
      "loss": 1.9641,
      "step": 5600
    },
    {
      "epoch": 0.6302662622177283,
      "grad_norm": 17.91148567199707,
      "learning_rate": 3.0421975471040126e-06,
      "loss": 2.0117,
      "step": 5610
    },
    {
      "epoch": 0.6313897314908438,
      "grad_norm": 12.102007865905762,
      "learning_rate": 3.025879872593077e-06,
      "loss": 1.7459,
      "step": 5620
    },
    {
      "epoch": 0.6325132007639591,
      "grad_norm": 10.943388938903809,
      "learning_rate": 3.0095870687921935e-06,
      "loss": 1.5243,
      "step": 5630
    },
    {
      "epoch": 0.6336366700370745,
      "grad_norm": 9.096487998962402,
      "learning_rate": 2.993319340964246e-06,
      "loss": 2.148,
      "step": 5640
    },
    {
      "epoch": 0.6347601393101898,
      "grad_norm": 7.847583770751953,
      "learning_rate": 2.9770768940562054e-06,
      "loss": 1.704,
      "step": 5650
    },
    {
      "epoch": 0.6358836085833053,
      "grad_norm": 11.597485542297363,
      "learning_rate": 2.9608599326965493e-06,
      "loss": 1.9361,
      "step": 5660
    },
    {
      "epoch": 0.6370070778564206,
      "grad_norm": 12.620391845703125,
      "learning_rate": 2.9446686611926717e-06,
      "loss": 1.9034,
      "step": 5670
    },
    {
      "epoch": 0.638130547129536,
      "grad_norm": 8.69233226776123,
      "learning_rate": 2.928503283528318e-06,
      "loss": 1.612,
      "step": 5680
    },
    {
      "epoch": 0.6392540164026513,
      "grad_norm": 7.237906455993652,
      "learning_rate": 2.912364003361016e-06,
      "loss": 2.1753,
      "step": 5690
    },
    {
      "epoch": 0.6403774856757668,
      "grad_norm": 9.08144760131836,
      "learning_rate": 2.8962510240195003e-06,
      "loss": 1.8333,
      "step": 5700
    },
    {
      "epoch": 0.6415009549488822,
      "grad_norm": 9.234427452087402,
      "learning_rate": 2.880164548501171e-06,
      "loss": 1.8175,
      "step": 5710
    },
    {
      "epoch": 0.6426244242219975,
      "grad_norm": 9.445748329162598,
      "learning_rate": 2.864104779469511e-06,
      "loss": 1.8546,
      "step": 5720
    },
    {
      "epoch": 0.6437478934951129,
      "grad_norm": 12.42515754699707,
      "learning_rate": 2.8480719192515453e-06,
      "loss": 2.2137,
      "step": 5730
    },
    {
      "epoch": 0.6448713627682283,
      "grad_norm": 7.891038417816162,
      "learning_rate": 2.832066169835299e-06,
      "loss": 1.236,
      "step": 5740
    },
    {
      "epoch": 0.6459948320413437,
      "grad_norm": 8.791963577270508,
      "learning_rate": 2.8160877328672393e-06,
      "loss": 1.7393,
      "step": 5750
    },
    {
      "epoch": 0.647118301314459,
      "grad_norm": 10.379776954650879,
      "learning_rate": 2.800136809649745e-06,
      "loss": 1.9712,
      "step": 5760
    },
    {
      "epoch": 0.6482417705875745,
      "grad_norm": 11.674628257751465,
      "learning_rate": 2.7842136011385624e-06,
      "loss": 2.1132,
      "step": 5770
    },
    {
      "epoch": 0.6493652398606898,
      "grad_norm": 12.866048812866211,
      "learning_rate": 2.7683183079402763e-06,
      "loss": 1.4255,
      "step": 5780
    },
    {
      "epoch": 0.6504887091338052,
      "grad_norm": 8.551448822021484,
      "learning_rate": 2.752451130309789e-06,
      "loss": 1.8288,
      "step": 5790
    },
    {
      "epoch": 0.6516121784069205,
      "grad_norm": 9.15695858001709,
      "learning_rate": 2.7366122681477893e-06,
      "loss": 1.919,
      "step": 5800
    },
    {
      "epoch": 0.652735647680036,
      "grad_norm": 19.199541091918945,
      "learning_rate": 2.7208019209982394e-06,
      "loss": 1.9453,
      "step": 5810
    },
    {
      "epoch": 0.6538591169531514,
      "grad_norm": 8.515425682067871,
      "learning_rate": 2.7050202880458552e-06,
      "loss": 1.6026,
      "step": 5820
    },
    {
      "epoch": 0.6549825862262667,
      "grad_norm": 9.024840354919434,
      "learning_rate": 2.6892675681135993e-06,
      "loss": 1.8214,
      "step": 5830
    },
    {
      "epoch": 0.6561060554993821,
      "grad_norm": 17.58331871032715,
      "learning_rate": 2.6735439596601824e-06,
      "loss": 1.9175,
      "step": 5840
    },
    {
      "epoch": 0.6572295247724975,
      "grad_norm": 12.243069648742676,
      "learning_rate": 2.657849660777555e-06,
      "loss": 2.0796,
      "step": 5850
    },
    {
      "epoch": 0.6583529940456129,
      "grad_norm": 11.954324722290039,
      "learning_rate": 2.6421848691884156e-06,
      "loss": 1.8384,
      "step": 5860
    },
    {
      "epoch": 0.6594764633187282,
      "grad_norm": 8.289488792419434,
      "learning_rate": 2.626549782243717e-06,
      "loss": 1.4765,
      "step": 5870
    },
    {
      "epoch": 0.6605999325918436,
      "grad_norm": 7.671854019165039,
      "learning_rate": 2.61094459692018e-06,
      "loss": 1.8643,
      "step": 5880
    },
    {
      "epoch": 0.661723401864959,
      "grad_norm": 8.698952674865723,
      "learning_rate": 2.595369509817818e-06,
      "loss": 2.0988,
      "step": 5890
    },
    {
      "epoch": 0.6628468711380744,
      "grad_norm": 11.489598274230957,
      "learning_rate": 2.5798247171574554e-06,
      "loss": 1.9978,
      "step": 5900
    },
    {
      "epoch": 0.6639703404111897,
      "grad_norm": 12.195201873779297,
      "learning_rate": 2.5643104147782505e-06,
      "loss": 1.4412,
      "step": 5910
    },
    {
      "epoch": 0.6650938096843051,
      "grad_norm": 12.434134483337402,
      "learning_rate": 2.54882679813524e-06,
      "loss": 1.888,
      "step": 5920
    },
    {
      "epoch": 0.6662172789574206,
      "grad_norm": 8.23184871673584,
      "learning_rate": 2.5333740622968638e-06,
      "loss": 1.949,
      "step": 5930
    },
    {
      "epoch": 0.6673407482305359,
      "grad_norm": 8.068069458007812,
      "learning_rate": 2.5179524019425193e-06,
      "loss": 1.8807,
      "step": 5940
    },
    {
      "epoch": 0.6684642175036513,
      "grad_norm": 9.164752006530762,
      "learning_rate": 2.5025620113601033e-06,
      "loss": 1.8136,
      "step": 5950
    },
    {
      "epoch": 0.6695876867767666,
      "grad_norm": 7.373599052429199,
      "learning_rate": 2.4872030844435575e-06,
      "loss": 2.0145,
      "step": 5960
    },
    {
      "epoch": 0.6707111560498821,
      "grad_norm": 9.954730033874512,
      "learning_rate": 2.471875814690441e-06,
      "loss": 1.6524,
      "step": 5970
    },
    {
      "epoch": 0.6718346253229974,
      "grad_norm": 6.865277290344238,
      "learning_rate": 2.4565803951994733e-06,
      "loss": 1.8981,
      "step": 5980
    },
    {
      "epoch": 0.6729580945961128,
      "grad_norm": 11.74741268157959,
      "learning_rate": 2.4413170186681277e-06,
      "loss": 1.6008,
      "step": 5990
    },
    {
      "epoch": 0.6740815638692281,
      "grad_norm": 7.3375444412231445,
      "learning_rate": 2.426085877390176e-06,
      "loss": 1.7674,
      "step": 6000
    },
    {
      "epoch": 0.6752050331423436,
      "grad_norm": 20.627193450927734,
      "learning_rate": 2.4108871632532783e-06,
      "loss": 1.9036,
      "step": 6010
    },
    {
      "epoch": 0.6763285024154589,
      "grad_norm": 5.30623722076416,
      "learning_rate": 2.395721067736573e-06,
      "loss": 1.8322,
      "step": 6020
    },
    {
      "epoch": 0.6774519716885743,
      "grad_norm": 9.07028865814209,
      "learning_rate": 2.3805877819082473e-06,
      "loss": 1.8426,
      "step": 6030
    },
    {
      "epoch": 0.6785754409616896,
      "grad_norm": 14.538786888122559,
      "learning_rate": 2.365487496423151e-06,
      "loss": 1.9682,
      "step": 6040
    },
    {
      "epoch": 0.6796989102348051,
      "grad_norm": 9.920615196228027,
      "learning_rate": 2.3504204015203745e-06,
      "loss": 1.5423,
      "step": 6050
    },
    {
      "epoch": 0.6808223795079205,
      "grad_norm": 7.614148139953613,
      "learning_rate": 2.33538668702086e-06,
      "loss": 1.9223,
      "step": 6060
    },
    {
      "epoch": 0.6819458487810358,
      "grad_norm": 12.18215560913086,
      "learning_rate": 2.3203865423250166e-06,
      "loss": 2.229,
      "step": 6070
    },
    {
      "epoch": 0.6830693180541512,
      "grad_norm": 8.77692699432373,
      "learning_rate": 2.305420156410325e-06,
      "loss": 1.9939,
      "step": 6080
    },
    {
      "epoch": 0.6841927873272666,
      "grad_norm": 7.286929607391357,
      "learning_rate": 2.2904877178289625e-06,
      "loss": 2.0508,
      "step": 6090
    },
    {
      "epoch": 0.685316256600382,
      "grad_norm": 9.378886222839355,
      "learning_rate": 2.275589414705422e-06,
      "loss": 1.7492,
      "step": 6100
    },
    {
      "epoch": 0.6864397258734973,
      "grad_norm": 8.45803451538086,
      "learning_rate": 2.2607254347341433e-06,
      "loss": 1.6072,
      "step": 6110
    },
    {
      "epoch": 0.6875631951466128,
      "grad_norm": 7.748202323913574,
      "learning_rate": 2.2458959651771557e-06,
      "loss": 1.9571,
      "step": 6120
    },
    {
      "epoch": 0.6886866644197281,
      "grad_norm": 12.131893157958984,
      "learning_rate": 2.2311011928617122e-06,
      "loss": 2.278,
      "step": 6130
    },
    {
      "epoch": 0.6898101336928435,
      "grad_norm": 11.274389266967773,
      "learning_rate": 2.2163413041779317e-06,
      "loss": 2.2323,
      "step": 6140
    },
    {
      "epoch": 0.6909336029659588,
      "grad_norm": 11.135852813720703,
      "learning_rate": 2.2016164850764636e-06,
      "loss": 2.0218,
      "step": 6150
    },
    {
      "epoch": 0.6920570722390743,
      "grad_norm": 8.830107688903809,
      "learning_rate": 2.18692692106613e-06,
      "loss": 1.8157,
      "step": 6160
    },
    {
      "epoch": 0.6931805415121897,
      "grad_norm": 8.211544036865234,
      "learning_rate": 2.1722727972116005e-06,
      "loss": 1.9069,
      "step": 6170
    },
    {
      "epoch": 0.694304010785305,
      "grad_norm": 13.450101852416992,
      "learning_rate": 2.1576542981310577e-06,
      "loss": 1.9504,
      "step": 6180
    },
    {
      "epoch": 0.6954274800584204,
      "grad_norm": 6.993392467498779,
      "learning_rate": 2.143071607993864e-06,
      "loss": 1.9339,
      "step": 6190
    },
    {
      "epoch": 0.6965509493315358,
      "grad_norm": 13.444253921508789,
      "learning_rate": 2.128524910518254e-06,
      "loss": 1.7419,
      "step": 6200
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 10.50500202178955,
      "learning_rate": 2.1140143889690062e-06,
      "loss": 1.8238,
      "step": 6210
    },
    {
      "epoch": 0.6987978878777665,
      "grad_norm": 8.399258613586426,
      "learning_rate": 2.0995402261551468e-06,
      "loss": 1.6441,
      "step": 6220
    },
    {
      "epoch": 0.6999213571508819,
      "grad_norm": 12.77738094329834,
      "learning_rate": 2.0851026044276405e-06,
      "loss": 1.9602,
      "step": 6230
    },
    {
      "epoch": 0.7010448264239973,
      "grad_norm": 10.606613159179688,
      "learning_rate": 2.070701705677089e-06,
      "loss": 1.7719,
      "step": 6240
    },
    {
      "epoch": 0.7021682956971127,
      "grad_norm": 23.856090545654297,
      "learning_rate": 2.0563377113314497e-06,
      "loss": 1.6692,
      "step": 6250
    },
    {
      "epoch": 0.703291764970228,
      "grad_norm": 10.713170051574707,
      "learning_rate": 2.042010802353739e-06,
      "loss": 1.7681,
      "step": 6260
    },
    {
      "epoch": 0.7044152342433434,
      "grad_norm": 8.599570274353027,
      "learning_rate": 2.027721159239762e-06,
      "loss": 1.7941,
      "step": 6270
    },
    {
      "epoch": 0.7055387035164589,
      "grad_norm": 9.892345428466797,
      "learning_rate": 2.013468962015834e-06,
      "loss": 2.1197,
      "step": 6280
    },
    {
      "epoch": 0.7066621727895742,
      "grad_norm": 12.718279838562012,
      "learning_rate": 1.9992543902365107e-06,
      "loss": 2.0254,
      "step": 6290
    },
    {
      "epoch": 0.7077856420626896,
      "grad_norm": 9.271171569824219,
      "learning_rate": 1.9850776229823314e-06,
      "loss": 1.7341,
      "step": 6300
    },
    {
      "epoch": 0.7089091113358049,
      "grad_norm": 8.193724632263184,
      "learning_rate": 1.9709388388575524e-06,
      "loss": 2.0627,
      "step": 6310
    },
    {
      "epoch": 0.7100325806089204,
      "grad_norm": 8.354681968688965,
      "learning_rate": 1.956838215987917e-06,
      "loss": 1.9238,
      "step": 6320
    },
    {
      "epoch": 0.7111560498820357,
      "grad_norm": 10.91665267944336,
      "learning_rate": 1.9427759320183876e-06,
      "loss": 1.5861,
      "step": 6330
    },
    {
      "epoch": 0.7122795191551511,
      "grad_norm": 8.963476181030273,
      "learning_rate": 1.9287521641109204e-06,
      "loss": 1.7874,
      "step": 6340
    },
    {
      "epoch": 0.7134029884282664,
      "grad_norm": 9.448357582092285,
      "learning_rate": 1.9147670889422355e-06,
      "loss": 1.7939,
      "step": 6350
    },
    {
      "epoch": 0.7145264577013819,
      "grad_norm": 8.444992065429688,
      "learning_rate": 1.9008208827015866e-06,
      "loss": 1.9261,
      "step": 6360
    },
    {
      "epoch": 0.7156499269744973,
      "grad_norm": 9.050003051757812,
      "learning_rate": 1.8869137210885384e-06,
      "loss": 1.8491,
      "step": 6370
    },
    {
      "epoch": 0.7167733962476126,
      "grad_norm": 7.52401876449585,
      "learning_rate": 1.8730457793107614e-06,
      "loss": 2.0589,
      "step": 6380
    },
    {
      "epoch": 0.717896865520728,
      "grad_norm": 6.996619701385498,
      "learning_rate": 1.8592172320818147e-06,
      "loss": 1.7085,
      "step": 6390
    },
    {
      "epoch": 0.7190203347938434,
      "grad_norm": 8.896697044372559,
      "learning_rate": 1.845428253618954e-06,
      "loss": 1.9439,
      "step": 6400
    },
    {
      "epoch": 0.7201438040669588,
      "grad_norm": 14.098182678222656,
      "learning_rate": 1.8316790176409327e-06,
      "loss": 1.9288,
      "step": 6410
    },
    {
      "epoch": 0.7212672733400741,
      "grad_norm": 9.639029502868652,
      "learning_rate": 1.8179696973658101e-06,
      "loss": 1.7238,
      "step": 6420
    },
    {
      "epoch": 0.7223907426131895,
      "grad_norm": 11.50593376159668,
      "learning_rate": 1.804300465508777e-06,
      "loss": 1.9933,
      "step": 6430
    },
    {
      "epoch": 0.7235142118863049,
      "grad_norm": 8.14026927947998,
      "learning_rate": 1.7906714942799696e-06,
      "loss": 1.6715,
      "step": 6440
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 8.117363929748535,
      "learning_rate": 1.7770829553823098e-06,
      "loss": 1.2954,
      "step": 6450
    },
    {
      "epoch": 0.7257611504325356,
      "grad_norm": 8.774995803833008,
      "learning_rate": 1.7635350200093393e-06,
      "loss": 2.0604,
      "step": 6460
    },
    {
      "epoch": 0.7268846197056511,
      "grad_norm": 10.33663272857666,
      "learning_rate": 1.7500278588430542e-06,
      "loss": 1.9055,
      "step": 6470
    },
    {
      "epoch": 0.7280080889787665,
      "grad_norm": 8.34945297241211,
      "learning_rate": 1.7365616420517694e-06,
      "loss": 1.9869,
      "step": 6480
    },
    {
      "epoch": 0.7291315582518818,
      "grad_norm": 8.20677661895752,
      "learning_rate": 1.7231365392879607e-06,
      "loss": 1.6705,
      "step": 6490
    },
    {
      "epoch": 0.7302550275249972,
      "grad_norm": 9.502873420715332,
      "learning_rate": 1.709752719686139e-06,
      "loss": 1.9156,
      "step": 6500
    },
    {
      "epoch": 0.7313784967981126,
      "grad_norm": 9.062634468078613,
      "learning_rate": 1.696410351860714e-06,
      "loss": 2.183,
      "step": 6510
    },
    {
      "epoch": 0.732501966071228,
      "grad_norm": 17.269596099853516,
      "learning_rate": 1.6831096039038642e-06,
      "loss": 1.5454,
      "step": 6520
    },
    {
      "epoch": 0.7336254353443433,
      "grad_norm": 8.505131721496582,
      "learning_rate": 1.6698506433834343e-06,
      "loss": 1.8451,
      "step": 6530
    },
    {
      "epoch": 0.7347489046174587,
      "grad_norm": 11.909459114074707,
      "learning_rate": 1.656633637340807e-06,
      "loss": 1.4114,
      "step": 6540
    },
    {
      "epoch": 0.7358723738905741,
      "grad_norm": 12.01524829864502,
      "learning_rate": 1.6434587522888112e-06,
      "loss": 1.8201,
      "step": 6550
    },
    {
      "epoch": 0.7369958431636895,
      "grad_norm": 7.662093639373779,
      "learning_rate": 1.6303261542096204e-06,
      "loss": 1.7416,
      "step": 6560
    },
    {
      "epoch": 0.7381193124368048,
      "grad_norm": 9.109177589416504,
      "learning_rate": 1.6172360085526567e-06,
      "loss": 1.8094,
      "step": 6570
    },
    {
      "epoch": 0.7392427817099202,
      "grad_norm": 10.382013320922852,
      "learning_rate": 1.6041884802325158e-06,
      "loss": 1.9779,
      "step": 6580
    },
    {
      "epoch": 0.7403662509830357,
      "grad_norm": 11.798736572265625,
      "learning_rate": 1.5911837336268775e-06,
      "loss": 1.9394,
      "step": 6590
    },
    {
      "epoch": 0.741489720256151,
      "grad_norm": 5.929141521453857,
      "learning_rate": 1.5782219325744475e-06,
      "loss": 2.1537,
      "step": 6600
    },
    {
      "epoch": 0.7426131895292664,
      "grad_norm": 11.280293464660645,
      "learning_rate": 1.5653032403728863e-06,
      "loss": 2.0107,
      "step": 6610
    },
    {
      "epoch": 0.7437366588023817,
      "grad_norm": 10.709630966186523,
      "learning_rate": 1.5524278197767484e-06,
      "loss": 2.1105,
      "step": 6620
    },
    {
      "epoch": 0.7448601280754972,
      "grad_norm": 8.485736846923828,
      "learning_rate": 1.539595832995442e-06,
      "loss": 1.6107,
      "step": 6630
    },
    {
      "epoch": 0.7459835973486125,
      "grad_norm": 9.849774360656738,
      "learning_rate": 1.526807441691175e-06,
      "loss": 1.7148,
      "step": 6640
    },
    {
      "epoch": 0.7471070666217279,
      "grad_norm": 6.788873672485352,
      "learning_rate": 1.5140628069769259e-06,
      "loss": 1.7633,
      "step": 6650
    },
    {
      "epoch": 0.7482305358948432,
      "grad_norm": 9.746015548706055,
      "learning_rate": 1.501362089414412e-06,
      "loss": 1.6996,
      "step": 6660
    },
    {
      "epoch": 0.7493540051679587,
      "grad_norm": 10.995272636413574,
      "learning_rate": 1.4887054490120611e-06,
      "loss": 1.771,
      "step": 6670
    },
    {
      "epoch": 0.750477474441074,
      "grad_norm": 10.253832817077637,
      "learning_rate": 1.476093045223006e-06,
      "loss": 1.7877,
      "step": 6680
    },
    {
      "epoch": 0.7516009437141894,
      "grad_norm": 7.350958824157715,
      "learning_rate": 1.463525036943067e-06,
      "loss": 1.4646,
      "step": 6690
    },
    {
      "epoch": 0.7527244129873047,
      "grad_norm": 11.729084968566895,
      "learning_rate": 1.4510015825087515e-06,
      "loss": 1.9379,
      "step": 6700
    },
    {
      "epoch": 0.7538478822604202,
      "grad_norm": 8.325094223022461,
      "learning_rate": 1.4385228396952654e-06,
      "loss": 1.647,
      "step": 6710
    },
    {
      "epoch": 0.7549713515335356,
      "grad_norm": 8.294844627380371,
      "learning_rate": 1.426088965714515e-06,
      "loss": 1.9444,
      "step": 6720
    },
    {
      "epoch": 0.7560948208066509,
      "grad_norm": 10.65860366821289,
      "learning_rate": 1.413700117213136e-06,
      "loss": 1.897,
      "step": 6730
    },
    {
      "epoch": 0.7572182900797663,
      "grad_norm": 7.5682878494262695,
      "learning_rate": 1.4013564502705167e-06,
      "loss": 1.8504,
      "step": 6740
    },
    {
      "epoch": 0.7583417593528817,
      "grad_norm": 8.715184211730957,
      "learning_rate": 1.3890581203968278e-06,
      "loss": 2.135,
      "step": 6750
    },
    {
      "epoch": 0.7594652286259971,
      "grad_norm": 10.423398971557617,
      "learning_rate": 1.3768052825310702e-06,
      "loss": 1.5825,
      "step": 6760
    },
    {
      "epoch": 0.7605886978991124,
      "grad_norm": 13.272968292236328,
      "learning_rate": 1.3645980910391143e-06,
      "loss": 2.0089,
      "step": 6770
    },
    {
      "epoch": 0.7617121671722279,
      "grad_norm": 8.161565780639648,
      "learning_rate": 1.3524366997117656e-06,
      "loss": 1.921,
      "step": 6780
    },
    {
      "epoch": 0.7628356364453432,
      "grad_norm": 9.049187660217285,
      "learning_rate": 1.3403212617628203e-06,
      "loss": 2.0942,
      "step": 6790
    },
    {
      "epoch": 0.7639591057184586,
      "grad_norm": 10.4116792678833,
      "learning_rate": 1.3282519298271335e-06,
      "loss": 1.7008,
      "step": 6800
    },
    {
      "epoch": 0.765082574991574,
      "grad_norm": 11.013097763061523,
      "learning_rate": 1.3162288559587045e-06,
      "loss": 1.9013,
      "step": 6810
    },
    {
      "epoch": 0.7662060442646894,
      "grad_norm": 8.71596622467041,
      "learning_rate": 1.3042521916287499e-06,
      "loss": 1.5988,
      "step": 6820
    },
    {
      "epoch": 0.7673295135378048,
      "grad_norm": 11.02618408203125,
      "learning_rate": 1.2923220877238069e-06,
      "loss": 2.026,
      "step": 6830
    },
    {
      "epoch": 0.7684529828109201,
      "grad_norm": 14.306381225585938,
      "learning_rate": 1.2804386945438263e-06,
      "loss": 1.7666,
      "step": 6840
    },
    {
      "epoch": 0.7695764520840355,
      "grad_norm": 10.912768363952637,
      "learning_rate": 1.2686021618002747e-06,
      "loss": 2.1704,
      "step": 6850
    },
    {
      "epoch": 0.7706999213571509,
      "grad_norm": 6.727649211883545,
      "learning_rate": 1.25681263861426e-06,
      "loss": 1.6086,
      "step": 6860
    },
    {
      "epoch": 0.7718233906302663,
      "grad_norm": 8.334065437316895,
      "learning_rate": 1.2450702735146392e-06,
      "loss": 1.9031,
      "step": 6870
    },
    {
      "epoch": 0.7729468599033816,
      "grad_norm": 9.260196685791016,
      "learning_rate": 1.2333752144361589e-06,
      "loss": 1.954,
      "step": 6880
    },
    {
      "epoch": 0.774070329176497,
      "grad_norm": 9.59164810180664,
      "learning_rate": 1.221727608717586e-06,
      "loss": 2.1296,
      "step": 6890
    },
    {
      "epoch": 0.7751937984496124,
      "grad_norm": 8.144453048706055,
      "learning_rate": 1.2101276030998499e-06,
      "loss": 2.0815,
      "step": 6900
    },
    {
      "epoch": 0.7763172677227278,
      "grad_norm": 12.497869491577148,
      "learning_rate": 1.1985753437241982e-06,
      "loss": 1.9816,
      "step": 6910
    },
    {
      "epoch": 0.7774407369958432,
      "grad_norm": 9.432714462280273,
      "learning_rate": 1.1870709761303501e-06,
      "loss": 1.7214,
      "step": 6920
    },
    {
      "epoch": 0.7785642062689585,
      "grad_norm": 10.499371528625488,
      "learning_rate": 1.17561464525467e-06,
      "loss": 1.8721,
      "step": 6930
    },
    {
      "epoch": 0.779687675542074,
      "grad_norm": 6.026659965515137,
      "learning_rate": 1.1642064954283367e-06,
      "loss": 1.8503,
      "step": 6940
    },
    {
      "epoch": 0.7808111448151893,
      "grad_norm": 8.70006275177002,
      "learning_rate": 1.152846670375523e-06,
      "loss": 1.9322,
      "step": 6950
    },
    {
      "epoch": 0.7819346140883047,
      "grad_norm": 12.538616180419922,
      "learning_rate": 1.1415353132115908e-06,
      "loss": 1.6494,
      "step": 6960
    },
    {
      "epoch": 0.78305808336142,
      "grad_norm": 12.105386734008789,
      "learning_rate": 1.1302725664412862e-06,
      "loss": 1.9838,
      "step": 6970
    },
    {
      "epoch": 0.7841815526345355,
      "grad_norm": 12.60402774810791,
      "learning_rate": 1.119058571956939e-06,
      "loss": 1.8688,
      "step": 6980
    },
    {
      "epoch": 0.7853050219076508,
      "grad_norm": 13.221790313720703,
      "learning_rate": 1.1078934710366845e-06,
      "loss": 1.8799,
      "step": 6990
    },
    {
      "epoch": 0.7864284911807662,
      "grad_norm": 8.960354804992676,
      "learning_rate": 1.0967774043426731e-06,
      "loss": 2.208,
      "step": 7000
    },
    {
      "epoch": 0.7875519604538815,
      "grad_norm": 8.201556205749512,
      "learning_rate": 1.0857105119193073e-06,
      "loss": 1.5943,
      "step": 7010
    },
    {
      "epoch": 0.788675429726997,
      "grad_norm": 10.892789840698242,
      "learning_rate": 1.0746929331914747e-06,
      "loss": 1.9873,
      "step": 7020
    },
    {
      "epoch": 0.7897988990001124,
      "grad_norm": 8.516510963439941,
      "learning_rate": 1.0637248069627847e-06,
      "loss": 1.954,
      "step": 7030
    },
    {
      "epoch": 0.7909223682732277,
      "grad_norm": 9.059487342834473,
      "learning_rate": 1.052806271413832e-06,
      "loss": 1.7536,
      "step": 7040
    },
    {
      "epoch": 0.7920458375463431,
      "grad_norm": 21.670909881591797,
      "learning_rate": 1.0419374641004438e-06,
      "loss": 1.889,
      "step": 7050
    },
    {
      "epoch": 0.7931693068194585,
      "grad_norm": 10.350090026855469,
      "learning_rate": 1.0311185219519548e-06,
      "loss": 1.6898,
      "step": 7060
    },
    {
      "epoch": 0.7942927760925739,
      "grad_norm": 8.069008827209473,
      "learning_rate": 1.020349581269482e-06,
      "loss": 2.0116,
      "step": 7070
    },
    {
      "epoch": 0.7954162453656892,
      "grad_norm": 8.26378345489502,
      "learning_rate": 1.0096307777241992e-06,
      "loss": 2.0029,
      "step": 7080
    },
    {
      "epoch": 0.7965397146388046,
      "grad_norm": 9.974112510681152,
      "learning_rate": 9.989622463556392e-07,
      "loss": 1.9694,
      "step": 7090
    },
    {
      "epoch": 0.79766318391192,
      "grad_norm": 9.899417877197266,
      "learning_rate": 9.883441215699824e-07,
      "loss": 1.8246,
      "step": 7100
    },
    {
      "epoch": 0.7987866531850354,
      "grad_norm": 10.326761245727539,
      "learning_rate": 9.777765371383712e-07,
      "loss": 2.0581,
      "step": 7110
    },
    {
      "epoch": 0.7999101224581507,
      "grad_norm": 8.867603302001953,
      "learning_rate": 9.672596261952228e-07,
      "loss": 1.6754,
      "step": 7120
    },
    {
      "epoch": 0.8010335917312662,
      "grad_norm": 8.824864387512207,
      "learning_rate": 9.567935212365447e-07,
      "loss": 1.9287,
      "step": 7130
    },
    {
      "epoch": 0.8021570610043816,
      "grad_norm": 9.857320785522461,
      "learning_rate": 9.463783541182786e-07,
      "loss": 1.749,
      "step": 7140
    },
    {
      "epoch": 0.8032805302774969,
      "grad_norm": 15.57907772064209,
      "learning_rate": 9.360142560546253e-07,
      "loss": 2.0026,
      "step": 7150
    },
    {
      "epoch": 0.8044039995506123,
      "grad_norm": 12.243664741516113,
      "learning_rate": 9.257013576164042e-07,
      "loss": 1.5431,
      "step": 7160
    },
    {
      "epoch": 0.8055274688237277,
      "grad_norm": 7.327106952667236,
      "learning_rate": 9.154397887294003e-07,
      "loss": 1.8845,
      "step": 7170
    },
    {
      "epoch": 0.8066509380968431,
      "grad_norm": 10.799113273620605,
      "learning_rate": 9.052296786727277e-07,
      "loss": 1.6744,
      "step": 7180
    },
    {
      "epoch": 0.8077744073699584,
      "grad_norm": 8.467461585998535,
      "learning_rate": 8.950711560772063e-07,
      "loss": 1.8881,
      "step": 7190
    },
    {
      "epoch": 0.8088978766430738,
      "grad_norm": 8.562946319580078,
      "learning_rate": 8.849643489237336e-07,
      "loss": 1.6441,
      "step": 7200
    },
    {
      "epoch": 0.8100213459161892,
      "grad_norm": 14.552583694458008,
      "learning_rate": 8.749093845416795e-07,
      "loss": 1.9081,
      "step": 7210
    },
    {
      "epoch": 0.8111448151893046,
      "grad_norm": 11.211530685424805,
      "learning_rate": 8.649063896072801e-07,
      "loss": 2.1948,
      "step": 7220
    },
    {
      "epoch": 0.8122682844624199,
      "grad_norm": 8.002920150756836,
      "learning_rate": 8.54955490142036e-07,
      "loss": 1.9811,
      "step": 7230
    },
    {
      "epoch": 0.8133917537355353,
      "grad_norm": 6.960336685180664,
      "learning_rate": 8.450568115111346e-07,
      "loss": 1.6806,
      "step": 7240
    },
    {
      "epoch": 0.8145152230086508,
      "grad_norm": 9.094659805297852,
      "learning_rate": 8.352104784218618e-07,
      "loss": 1.6383,
      "step": 7250
    },
    {
      "epoch": 0.8156386922817661,
      "grad_norm": 9.633805274963379,
      "learning_rate": 8.254166149220361e-07,
      "loss": 2.1085,
      "step": 7260
    },
    {
      "epoch": 0.8167621615548815,
      "grad_norm": 11.215632438659668,
      "learning_rate": 8.156753443984466e-07,
      "loss": 1.2593,
      "step": 7270
    },
    {
      "epoch": 0.8178856308279968,
      "grad_norm": 6.355541229248047,
      "learning_rate": 8.059867895752909e-07,
      "loss": 2.2036,
      "step": 7280
    },
    {
      "epoch": 0.8190091001011123,
      "grad_norm": 9.404335975646973,
      "learning_rate": 7.963510725126395e-07,
      "loss": 1.6969,
      "step": 7290
    },
    {
      "epoch": 0.8201325693742276,
      "grad_norm": 5.913318634033203,
      "learning_rate": 7.86768314604891e-07,
      "loss": 1.7172,
      "step": 7300
    },
    {
      "epoch": 0.821256038647343,
      "grad_norm": 10.080145835876465,
      "learning_rate": 7.772386365792422e-07,
      "loss": 1.6545,
      "step": 7310
    },
    {
      "epoch": 0.8223795079204583,
      "grad_norm": 9.70013427734375,
      "learning_rate": 7.677621584941741e-07,
      "loss": 1.9225,
      "step": 7320
    },
    {
      "epoch": 0.8235029771935738,
      "grad_norm": 7.613183975219727,
      "learning_rate": 7.583389997379304e-07,
      "loss": 1.3077,
      "step": 7330
    },
    {
      "epoch": 0.8246264464666891,
      "grad_norm": 7.596508502960205,
      "learning_rate": 7.489692790270203e-07,
      "loss": 1.6707,
      "step": 7340
    },
    {
      "epoch": 0.8257499157398045,
      "grad_norm": 7.877926349639893,
      "learning_rate": 7.39653114404722e-07,
      "loss": 1.7577,
      "step": 7350
    },
    {
      "epoch": 0.8268733850129198,
      "grad_norm": 10.581038475036621,
      "learning_rate": 7.303906232395874e-07,
      "loss": 1.755,
      "step": 7360
    },
    {
      "epoch": 0.8279968542860353,
      "grad_norm": 8.683981895446777,
      "learning_rate": 7.211819222239785e-07,
      "loss": 1.8919,
      "step": 7370
    },
    {
      "epoch": 0.8291203235591507,
      "grad_norm": 11.061576843261719,
      "learning_rate": 7.120271273725815e-07,
      "loss": 1.7964,
      "step": 7380
    },
    {
      "epoch": 0.830243792832266,
      "grad_norm": 7.351523399353027,
      "learning_rate": 7.029263540209563e-07,
      "loss": 1.9055,
      "step": 7390
    },
    {
      "epoch": 0.8313672621053814,
      "grad_norm": 11.663301467895508,
      "learning_rate": 6.938797168240797e-07,
      "loss": 2.0937,
      "step": 7400
    },
    {
      "epoch": 0.8324907313784968,
      "grad_norm": 8.035467147827148,
      "learning_rate": 6.848873297548975e-07,
      "loss": 1.674,
      "step": 7410
    },
    {
      "epoch": 0.8336142006516122,
      "grad_norm": 8.804377555847168,
      "learning_rate": 6.759493061028966e-07,
      "loss": 2.0536,
      "step": 7420
    },
    {
      "epoch": 0.8347376699247275,
      "grad_norm": 9.113697052001953,
      "learning_rate": 6.670657584726681e-07,
      "loss": 1.9061,
      "step": 7430
    },
    {
      "epoch": 0.8358611391978429,
      "grad_norm": 11.641327857971191,
      "learning_rate": 6.582367987824978e-07,
      "loss": 2.4871,
      "step": 7440
    },
    {
      "epoch": 0.8369846084709583,
      "grad_norm": 8.18364429473877,
      "learning_rate": 6.494625382629505e-07,
      "loss": 1.5638,
      "step": 7450
    },
    {
      "epoch": 0.8381080777440737,
      "grad_norm": 9.283616065979004,
      "learning_rate": 6.407430874554682e-07,
      "loss": 1.9436,
      "step": 7460
    },
    {
      "epoch": 0.839231547017189,
      "grad_norm": 7.262386798858643,
      "learning_rate": 6.320785562109843e-07,
      "loss": 2.0803,
      "step": 7470
    },
    {
      "epoch": 0.8403550162903045,
      "grad_norm": 8.969895362854004,
      "learning_rate": 6.234690536885291e-07,
      "loss": 1.8427,
      "step": 7480
    },
    {
      "epoch": 0.8414784855634199,
      "grad_norm": 8.419356346130371,
      "learning_rate": 6.149146883538637e-07,
      "loss": 1.9921,
      "step": 7490
    },
    {
      "epoch": 0.8426019548365352,
      "grad_norm": 11.274616241455078,
      "learning_rate": 6.064155679781114e-07,
      "loss": 2.0923,
      "step": 7500
    },
    {
      "epoch": 0.8437254241096506,
      "grad_norm": 8.393020629882812,
      "learning_rate": 5.979717996363943e-07,
      "loss": 1.7847,
      "step": 7510
    },
    {
      "epoch": 0.844848893382766,
      "grad_norm": 8.941000938415527,
      "learning_rate": 5.895834897064934e-07,
      "loss": 1.9798,
      "step": 7520
    },
    {
      "epoch": 0.8459723626558814,
      "grad_norm": 14.660059928894043,
      "learning_rate": 5.812507438674986e-07,
      "loss": 1.9527,
      "step": 7530
    },
    {
      "epoch": 0.8470958319289967,
      "grad_norm": 10.604792594909668,
      "learning_rate": 5.729736670984875e-07,
      "loss": 1.9697,
      "step": 7540
    },
    {
      "epoch": 0.8482193012021121,
      "grad_norm": 9.487040519714355,
      "learning_rate": 5.647523636771962e-07,
      "loss": 1.861,
      "step": 7550
    },
    {
      "epoch": 0.8493427704752275,
      "grad_norm": 8.814273834228516,
      "learning_rate": 5.565869371787047e-07,
      "loss": 1.8311,
      "step": 7560
    },
    {
      "epoch": 0.8504662397483429,
      "grad_norm": 10.376720428466797,
      "learning_rate": 5.484774904741353e-07,
      "loss": 1.808,
      "step": 7570
    },
    {
      "epoch": 0.8515897090214583,
      "grad_norm": 9.560242652893066,
      "learning_rate": 5.404241257293596e-07,
      "loss": 1.7493,
      "step": 7580
    },
    {
      "epoch": 0.8527131782945736,
      "grad_norm": 14.215736389160156,
      "learning_rate": 5.324269444037022e-07,
      "loss": 1.5571,
      "step": 7590
    },
    {
      "epoch": 0.8538366475676891,
      "grad_norm": 8.793004035949707,
      "learning_rate": 5.244860472486724e-07,
      "loss": 1.4294,
      "step": 7600
    },
    {
      "epoch": 0.8549601168408044,
      "grad_norm": 7.405080318450928,
      "learning_rate": 5.166015343066854e-07,
      "loss": 1.9206,
      "step": 7610
    },
    {
      "epoch": 0.8560835861139198,
      "grad_norm": 7.6769561767578125,
      "learning_rate": 5.087735049098114e-07,
      "loss": 1.6782,
      "step": 7620
    },
    {
      "epoch": 0.8572070553870351,
      "grad_norm": 10.133450508117676,
      "learning_rate": 5.010020576785174e-07,
      "loss": 1.9891,
      "step": 7630
    },
    {
      "epoch": 0.8583305246601506,
      "grad_norm": 14.814391136169434,
      "learning_rate": 4.932872905204256e-07,
      "loss": 1.9826,
      "step": 7640
    },
    {
      "epoch": 0.8594539939332659,
      "grad_norm": 6.881682395935059,
      "learning_rate": 4.856293006290858e-07,
      "loss": 1.864,
      "step": 7650
    },
    {
      "epoch": 0.8605774632063813,
      "grad_norm": 7.937623977661133,
      "learning_rate": 4.7802818448274e-07,
      "loss": 1.7597,
      "step": 7660
    },
    {
      "epoch": 0.8617009324794966,
      "grad_norm": 14.763691902160645,
      "learning_rate": 4.704840378431191e-07,
      "loss": 1.931,
      "step": 7670
    },
    {
      "epoch": 0.8628244017526121,
      "grad_norm": 12.724145889282227,
      "learning_rate": 4.6299695575422796e-07,
      "loss": 1.9811,
      "step": 7680
    },
    {
      "epoch": 0.8639478710257275,
      "grad_norm": 7.382561683654785,
      "learning_rate": 4.5556703254115043e-07,
      "loss": 1.5718,
      "step": 7690
    },
    {
      "epoch": 0.8650713402988428,
      "grad_norm": 7.105793476104736,
      "learning_rate": 4.4819436180886245e-07,
      "loss": 1.7475,
      "step": 7700
    },
    {
      "epoch": 0.8661948095719582,
      "grad_norm": 9.756324768066406,
      "learning_rate": 4.408790364410498e-07,
      "loss": 1.8224,
      "step": 7710
    },
    {
      "epoch": 0.8673182788450736,
      "grad_norm": 9.873626708984375,
      "learning_rate": 4.336211485989422e-07,
      "loss": 1.6778,
      "step": 7720
    },
    {
      "epoch": 0.868441748118189,
      "grad_norm": 14.4971284866333,
      "learning_rate": 4.264207897201489e-07,
      "loss": 1.7334,
      "step": 7730
    },
    {
      "epoch": 0.8695652173913043,
      "grad_norm": 7.470471382141113,
      "learning_rate": 4.192780505175059e-07,
      "loss": 1.8016,
      "step": 7740
    },
    {
      "epoch": 0.8706886866644197,
      "grad_norm": 9.873832702636719,
      "learning_rate": 4.121930209779379e-07,
      "loss": 1.6354,
      "step": 7750
    },
    {
      "epoch": 0.8718121559375351,
      "grad_norm": 17.428739547729492,
      "learning_rate": 4.051657903613171e-07,
      "loss": 1.9687,
      "step": 7760
    },
    {
      "epoch": 0.8729356252106505,
      "grad_norm": 10.112488746643066,
      "learning_rate": 3.981964471993471e-07,
      "loss": 2.256,
      "step": 7770
    },
    {
      "epoch": 0.8740590944837658,
      "grad_norm": 12.866090774536133,
      "learning_rate": 3.9128507929444284e-07,
      "loss": 2.1118,
      "step": 7780
    },
    {
      "epoch": 0.8751825637568813,
      "grad_norm": 10.8961181640625,
      "learning_rate": 3.8443177371862374e-07,
      "loss": 1.5807,
      "step": 7790
    },
    {
      "epoch": 0.8763060330299967,
      "grad_norm": 8.162384033203125,
      "learning_rate": 3.7763661681241735e-07,
      "loss": 1.6063,
      "step": 7800
    },
    {
      "epoch": 0.877429502303112,
      "grad_norm": 6.574338912963867,
      "learning_rate": 3.7089969418377446e-07,
      "loss": 1.7245,
      "step": 7810
    },
    {
      "epoch": 0.8785529715762274,
      "grad_norm": 13.061553955078125,
      "learning_rate": 3.6422109070698817e-07,
      "loss": 1.8205,
      "step": 7820
    },
    {
      "epoch": 0.8796764408493428,
      "grad_norm": 10.467901229858398,
      "learning_rate": 3.5760089052162494e-07,
      "loss": 1.9529,
      "step": 7830
    },
    {
      "epoch": 0.8807999101224582,
      "grad_norm": 14.614137649536133,
      "learning_rate": 3.510391770314636e-07,
      "loss": 1.5319,
      "step": 7840
    },
    {
      "epoch": 0.8819233793955735,
      "grad_norm": 11.019767761230469,
      "learning_rate": 3.4453603290344417e-07,
      "loss": 2.2309,
      "step": 7850
    },
    {
      "epoch": 0.8830468486686889,
      "grad_norm": 11.391155242919922,
      "learning_rate": 3.3809154006663127e-07,
      "loss": 2.1962,
      "step": 7860
    },
    {
      "epoch": 0.8841703179418043,
      "grad_norm": 10.929340362548828,
      "learning_rate": 3.317057797111761e-07,
      "loss": 1.7835,
      "step": 7870
    },
    {
      "epoch": 0.8852937872149197,
      "grad_norm": 6.9397735595703125,
      "learning_rate": 3.253788322872975e-07,
      "loss": 1.5879,
      "step": 7880
    },
    {
      "epoch": 0.886417256488035,
      "grad_norm": 9.309680938720703,
      "learning_rate": 3.1911077750426456e-07,
      "loss": 1.9772,
      "step": 7890
    },
    {
      "epoch": 0.8875407257611504,
      "grad_norm": 8.002951622009277,
      "learning_rate": 3.1290169432939497e-07,
      "loss": 2.1161,
      "step": 7900
    },
    {
      "epoch": 0.8886641950342659,
      "grad_norm": 10.297381401062012,
      "learning_rate": 3.067516609870641e-07,
      "loss": 1.8586,
      "step": 7910
    },
    {
      "epoch": 0.8897876643073812,
      "grad_norm": 10.961956024169922,
      "learning_rate": 3.006607549577084e-07,
      "loss": 2.0051,
      "step": 7920
    },
    {
      "epoch": 0.8909111335804966,
      "grad_norm": 12.715731620788574,
      "learning_rate": 2.946290529768625e-07,
      "loss": 1.8885,
      "step": 7930
    },
    {
      "epoch": 0.8920346028536119,
      "grad_norm": 14.352272987365723,
      "learning_rate": 2.8865663103418096e-07,
      "loss": 2.1788,
      "step": 7940
    },
    {
      "epoch": 0.8931580721267274,
      "grad_norm": 8.43819808959961,
      "learning_rate": 2.8274356437248905e-07,
      "loss": 1.9631,
      "step": 7950
    },
    {
      "epoch": 0.8942815413998427,
      "grad_norm": 8.176345825195312,
      "learning_rate": 2.7688992748683254e-07,
      "loss": 1.8582,
      "step": 7960
    },
    {
      "epoch": 0.8954050106729581,
      "grad_norm": 20.805509567260742,
      "learning_rate": 2.710957941235354e-07,
      "loss": 1.9679,
      "step": 7970
    },
    {
      "epoch": 0.8965284799460734,
      "grad_norm": 19.74055290222168,
      "learning_rate": 2.6536123727927574e-07,
      "loss": 1.7828,
      "step": 7980
    },
    {
      "epoch": 0.8976519492191889,
      "grad_norm": 19.873220443725586,
      "learning_rate": 2.596863292001639e-07,
      "loss": 1.9737,
      "step": 7990
    },
    {
      "epoch": 0.8987754184923042,
      "grad_norm": 10.846283912658691,
      "learning_rate": 2.540711413808328e-07,
      "loss": 2.0424,
      "step": 8000
    },
    {
      "epoch": 0.8998988877654196,
      "grad_norm": 11.831643104553223,
      "learning_rate": 2.4851574456353724e-07,
      "loss": 1.7979,
      "step": 8010
    },
    {
      "epoch": 0.901022357038535,
      "grad_norm": 11.589850425720215,
      "learning_rate": 2.4302020873726126e-07,
      "loss": 1.9171,
      "step": 8020
    },
    {
      "epoch": 0.9021458263116504,
      "grad_norm": 10.59926700592041,
      "learning_rate": 2.3758460313683784e-07,
      "loss": 1.7287,
      "step": 8030
    },
    {
      "epoch": 0.9032692955847658,
      "grad_norm": 7.955044269561768,
      "learning_rate": 2.3220899624207704e-07,
      "loss": 1.8666,
      "step": 8040
    },
    {
      "epoch": 0.9043927648578811,
      "grad_norm": 6.015482425689697,
      "learning_rate": 2.2689345577690315e-07,
      "loss": 1.4657,
      "step": 8050
    },
    {
      "epoch": 0.9055162341309965,
      "grad_norm": 18.711824417114258,
      "learning_rate": 2.2163804870849958e-07,
      "loss": 2.0484,
      "step": 8060
    },
    {
      "epoch": 0.9066397034041119,
      "grad_norm": 7.0234150886535645,
      "learning_rate": 2.1644284124646754e-07,
      "loss": 1.8646,
      "step": 8070
    },
    {
      "epoch": 0.9077631726772273,
      "grad_norm": 8.901244163513184,
      "learning_rate": 2.113078988419892e-07,
      "loss": 1.9095,
      "step": 8080
    },
    {
      "epoch": 0.9088866419503426,
      "grad_norm": 10.163073539733887,
      "learning_rate": 2.0623328618700645e-07,
      "loss": 1.8738,
      "step": 8090
    },
    {
      "epoch": 0.910010111223458,
      "grad_norm": 8.963652610778809,
      "learning_rate": 2.01219067213404e-07,
      "loss": 1.8327,
      "step": 8100
    },
    {
      "epoch": 0.9111335804965734,
      "grad_norm": 11.100811004638672,
      "learning_rate": 1.962653050922042e-07,
      "loss": 1.7654,
      "step": 8110
    },
    {
      "epoch": 0.9122570497696888,
      "grad_norm": 56.90739440917969,
      "learning_rate": 1.9137206223277084e-07,
      "loss": 2.2527,
      "step": 8120
    },
    {
      "epoch": 0.9133805190428042,
      "grad_norm": 9.948807716369629,
      "learning_rate": 1.8653940028202255e-07,
      "loss": 2.0121,
      "step": 8130
    },
    {
      "epoch": 0.9145039883159196,
      "grad_norm": 10.51822566986084,
      "learning_rate": 1.8176738012365857e-07,
      "loss": 1.8228,
      "step": 8140
    },
    {
      "epoch": 0.915627457589035,
      "grad_norm": 8.682353973388672,
      "learning_rate": 1.770560618773881e-07,
      "loss": 2.0293,
      "step": 8150
    },
    {
      "epoch": 0.9167509268621503,
      "grad_norm": 7.792960166931152,
      "learning_rate": 1.7240550489817652e-07,
      "loss": 1.8242,
      "step": 8160
    },
    {
      "epoch": 0.9178743961352657,
      "grad_norm": 9.20119571685791,
      "learning_rate": 1.678157677754949e-07,
      "loss": 1.9044,
      "step": 8170
    },
    {
      "epoch": 0.9189978654083811,
      "grad_norm": 17.9133243560791,
      "learning_rate": 1.632869083325811e-07,
      "loss": 2.0449,
      "step": 8180
    },
    {
      "epoch": 0.9201213346814965,
      "grad_norm": 10.792375564575195,
      "learning_rate": 1.5881898362571756e-07,
      "loss": 2.0191,
      "step": 8190
    },
    {
      "epoch": 0.9212448039546118,
      "grad_norm": 8.279875755310059,
      "learning_rate": 1.5441204994350257e-07,
      "loss": 1.5707,
      "step": 8200
    },
    {
      "epoch": 0.9223682732277272,
      "grad_norm": 7.855179786682129,
      "learning_rate": 1.5006616280615116e-07,
      "loss": 1.9975,
      "step": 8210
    },
    {
      "epoch": 0.9234917425008426,
      "grad_norm": 11.40385913848877,
      "learning_rate": 1.4578137696478756e-07,
      "loss": 1.9749,
      "step": 8220
    },
    {
      "epoch": 0.924615211773958,
      "grad_norm": 14.580044746398926,
      "learning_rate": 1.4155774640076004e-07,
      "loss": 1.9096,
      "step": 8230
    },
    {
      "epoch": 0.9257386810470734,
      "grad_norm": 12.47765064239502,
      "learning_rate": 1.3739532432496094e-07,
      "loss": 2.0855,
      "step": 8240
    },
    {
      "epoch": 0.9268621503201887,
      "grad_norm": 16.97932243347168,
      "learning_rate": 1.3329416317715282e-07,
      "loss": 2.0526,
      "step": 8250
    },
    {
      "epoch": 0.9279856195933042,
      "grad_norm": 6.777271747589111,
      "learning_rate": 1.2925431462531056e-07,
      "loss": 1.9556,
      "step": 8260
    },
    {
      "epoch": 0.9291090888664195,
      "grad_norm": 9.437838554382324,
      "learning_rate": 1.2527582956497032e-07,
      "loss": 1.9049,
      "step": 8270
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 11.481037139892578,
      "learning_rate": 1.213587581185882e-07,
      "loss": 1.855,
      "step": 8280
    },
    {
      "epoch": 0.9313560274126502,
      "grad_norm": 11.344868659973145,
      "learning_rate": 1.1750314963490772e-07,
      "loss": 2.0715,
      "step": 8290
    },
    {
      "epoch": 0.9324794966857657,
      "grad_norm": 9.338906288146973,
      "learning_rate": 1.1370905268833942e-07,
      "loss": 1.8686,
      "step": 8300
    },
    {
      "epoch": 0.933602965958881,
      "grad_norm": 7.07172155380249,
      "learning_rate": 1.0997651507834605e-07,
      "loss": 1.5017,
      "step": 8310
    },
    {
      "epoch": 0.9347264352319964,
      "grad_norm": 7.8811492919921875,
      "learning_rate": 1.0630558382884626e-07,
      "loss": 2.1616,
      "step": 8320
    },
    {
      "epoch": 0.9358499045051117,
      "grad_norm": 9.192548751831055,
      "learning_rate": 1.0269630518761564e-07,
      "loss": 1.8149,
      "step": 8330
    },
    {
      "epoch": 0.9369733737782272,
      "grad_norm": 9.7848482131958,
      "learning_rate": 9.914872462570946e-08,
      "loss": 1.5756,
      "step": 8340
    },
    {
      "epoch": 0.9380968430513426,
      "grad_norm": 9.893210411071777,
      "learning_rate": 9.566288683688418e-08,
      "loss": 1.7906,
      "step": 8350
    },
    {
      "epoch": 0.9392203123244579,
      "grad_norm": 10.461893081665039,
      "learning_rate": 9.223883573704018e-08,
      "loss": 1.8164,
      "step": 8360
    },
    {
      "epoch": 0.9403437815975733,
      "grad_norm": 13.207879066467285,
      "learning_rate": 8.88766144636638e-08,
      "loss": 1.6581,
      "step": 8370
    },
    {
      "epoch": 0.9414672508706887,
      "grad_norm": 12.74217414855957,
      "learning_rate": 8.557626537528841e-08,
      "loss": 2.1845,
      "step": 8380
    },
    {
      "epoch": 0.9425907201438041,
      "grad_norm": 10.109731674194336,
      "learning_rate": 8.233783005095641e-08,
      "loss": 1.6195,
      "step": 8390
    },
    {
      "epoch": 0.9437141894169194,
      "grad_norm": 10.393546104431152,
      "learning_rate": 7.916134928969699e-08,
      "loss": 2.1928,
      "step": 8400
    },
    {
      "epoch": 0.9448376586900348,
      "grad_norm": 9.310968399047852,
      "learning_rate": 7.604686311001307e-08,
      "loss": 1.7991,
      "step": 8410
    },
    {
      "epoch": 0.9459611279631502,
      "grad_norm": 20.127155303955078,
      "learning_rate": 7.29944107493763e-08,
      "loss": 1.8231,
      "step": 8420
    },
    {
      "epoch": 0.9470845972362656,
      "grad_norm": 10.16783332824707,
      "learning_rate": 7.000403066373396e-08,
      "loss": 2.1484,
      "step": 8430
    },
    {
      "epoch": 0.9482080665093809,
      "grad_norm": 10.333292961120605,
      "learning_rate": 6.707576052702169e-08,
      "loss": 1.4105,
      "step": 8440
    },
    {
      "epoch": 0.9493315357824963,
      "grad_norm": 11.250012397766113,
      "learning_rate": 6.420963723069162e-08,
      "loss": 2.0244,
      "step": 8450
    },
    {
      "epoch": 0.9504550050556118,
      "grad_norm": 8.541775703430176,
      "learning_rate": 6.14056968832455e-08,
      "loss": 1.632,
      "step": 8460
    },
    {
      "epoch": 0.9515784743287271,
      "grad_norm": 10.504714012145996,
      "learning_rate": 5.866397480978225e-08,
      "loss": 1.7495,
      "step": 8470
    },
    {
      "epoch": 0.9527019436018425,
      "grad_norm": 9.238593101501465,
      "learning_rate": 5.598450555155066e-08,
      "loss": 1.7611,
      "step": 8480
    },
    {
      "epoch": 0.9538254128749579,
      "grad_norm": 21.13721466064453,
      "learning_rate": 5.336732286551516e-08,
      "loss": 1.6904,
      "step": 8490
    },
    {
      "epoch": 0.9549488821480733,
      "grad_norm": 13.883552551269531,
      "learning_rate": 5.0812459723930674e-08,
      "loss": 2.0784,
      "step": 8500
    },
    {
      "epoch": 0.9560723514211886,
      "grad_norm": 10.04124927520752,
      "learning_rate": 4.8319948313925725e-08,
      "loss": 1.6836,
      "step": 8510
    },
    {
      "epoch": 0.957195820694304,
      "grad_norm": 8.337298393249512,
      "learning_rate": 4.588982003710052e-08,
      "loss": 2.2026,
      "step": 8520
    },
    {
      "epoch": 0.9583192899674194,
      "grad_norm": 11.351961135864258,
      "learning_rate": 4.3522105509127835e-08,
      "loss": 1.4974,
      "step": 8530
    },
    {
      "epoch": 0.9594427592405348,
      "grad_norm": 7.869791030883789,
      "learning_rate": 4.12168345593672e-08,
      "loss": 1.6734,
      "step": 8540
    },
    {
      "epoch": 0.9605662285136501,
      "grad_norm": 11.662247657775879,
      "learning_rate": 3.8974036230493005e-08,
      "loss": 1.8845,
      "step": 8550
    },
    {
      "epoch": 0.9616896977867655,
      "grad_norm": 7.954085826873779,
      "learning_rate": 3.679373877812364e-08,
      "loss": 1.7299,
      "step": 8560
    },
    {
      "epoch": 0.962813167059881,
      "grad_norm": 8.048303604125977,
      "learning_rate": 3.4675969670469603e-08,
      "loss": 1.9082,
      "step": 8570
    },
    {
      "epoch": 0.9639366363329963,
      "grad_norm": 11.95497989654541,
      "learning_rate": 3.2620755587985386e-08,
      "loss": 1.8633,
      "step": 8580
    },
    {
      "epoch": 0.9650601056061117,
      "grad_norm": 14.933345794677734,
      "learning_rate": 3.062812242303148e-08,
      "loss": 1.9261,
      "step": 8590
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 6.976693153381348,
      "learning_rate": 2.8698095279554026e-08,
      "loss": 1.6957,
      "step": 8600
    },
    {
      "epoch": 0.9673070441523425,
      "grad_norm": 12.46120548248291,
      "learning_rate": 2.6830698472761762e-08,
      "loss": 1.6558,
      "step": 8610
    },
    {
      "epoch": 0.9684305134254578,
      "grad_norm": 10.82377815246582,
      "learning_rate": 2.5025955528824587e-08,
      "loss": 1.3667,
      "step": 8620
    },
    {
      "epoch": 0.9695539826985732,
      "grad_norm": 11.228748321533203,
      "learning_rate": 2.328388918457547e-08,
      "loss": 1.6594,
      "step": 8630
    },
    {
      "epoch": 0.9706774519716885,
      "grad_norm": 10.100449562072754,
      "learning_rate": 2.1604521387222356e-08,
      "loss": 1.4648,
      "step": 8640
    },
    {
      "epoch": 0.971800921244804,
      "grad_norm": 9.011208534240723,
      "learning_rate": 1.998787329407448e-08,
      "loss": 2.0184,
      "step": 8650
    },
    {
      "epoch": 0.9729243905179193,
      "grad_norm": 8.260461807250977,
      "learning_rate": 1.843396527227481e-08,
      "loss": 1.6642,
      "step": 8660
    },
    {
      "epoch": 0.9740478597910347,
      "grad_norm": 10.666343688964844,
      "learning_rate": 1.6942816898543045e-08,
      "loss": 1.9949,
      "step": 8670
    },
    {
      "epoch": 0.97517132906415,
      "grad_norm": 7.998516082763672,
      "learning_rate": 1.551444695892801e-08,
      "loss": 1.7373,
      "step": 8680
    },
    {
      "epoch": 0.9762947983372655,
      "grad_norm": 8.927044868469238,
      "learning_rate": 1.4148873448573408e-08,
      "loss": 1.5858,
      "step": 8690
    },
    {
      "epoch": 0.9774182676103809,
      "grad_norm": 8.447409629821777,
      "learning_rate": 1.2846113571489127e-08,
      "loss": 1.7906,
      "step": 8700
    },
    {
      "epoch": 0.9785417368834962,
      "grad_norm": 9.64366626739502,
      "learning_rate": 1.1606183740336396e-08,
      "loss": 1.7948,
      "step": 8710
    },
    {
      "epoch": 0.9796652061566116,
      "grad_norm": 7.585093975067139,
      "learning_rate": 1.042909957621796e-08,
      "loss": 1.8786,
      "step": 8720
    },
    {
      "epoch": 0.980788675429727,
      "grad_norm": 12.980116844177246,
      "learning_rate": 9.314875908484345e-09,
      "loss": 2.0829,
      "step": 8730
    },
    {
      "epoch": 0.9819121447028424,
      "grad_norm": 9.401479721069336,
      "learning_rate": 8.263526774546227e-09,
      "loss": 1.799,
      "step": 8740
    },
    {
      "epoch": 0.9830356139759577,
      "grad_norm": 10.764753341674805,
      "learning_rate": 7.275065419696248e-09,
      "loss": 1.7997,
      "step": 8750
    },
    {
      "epoch": 0.9841590832490731,
      "grad_norm": 9.347135543823242,
      "learning_rate": 6.349504296943587e-09,
      "loss": 2.071,
      "step": 8760
    },
    {
      "epoch": 0.9852825525221885,
      "grad_norm": 10.846684455871582,
      "learning_rate": 5.486855066855756e-09,
      "loss": 1.7538,
      "step": 8770
    },
    {
      "epoch": 0.9864060217953039,
      "grad_norm": 7.451844215393066,
      "learning_rate": 4.68712859741427e-09,
      "loss": 2.2517,
      "step": 8780
    },
    {
      "epoch": 0.9875294910684193,
      "grad_norm": 7.316237449645996,
      "learning_rate": 3.950334963873648e-09,
      "loss": 1.9319,
      "step": 8790
    },
    {
      "epoch": 0.9886529603415347,
      "grad_norm": 9.002609252929688,
      "learning_rate": 3.276483448638734e-09,
      "loss": 1.6172,
      "step": 8800
    },
    {
      "epoch": 0.9897764296146501,
      "grad_norm": 8.300418853759766,
      "learning_rate": 2.6655825411453506e-09,
      "loss": 1.7703,
      "step": 8810
    },
    {
      "epoch": 0.9908998988877654,
      "grad_norm": 11.027506828308105,
      "learning_rate": 2.1176399377526023e-09,
      "loss": 1.7449,
      "step": 8820
    },
    {
      "epoch": 0.9920233681608808,
      "grad_norm": 10.037849426269531,
      "learning_rate": 1.632662541649066e-09,
      "loss": 1.9006,
      "step": 8830
    },
    {
      "epoch": 0.9931468374339962,
      "grad_norm": 9.696293830871582,
      "learning_rate": 1.2106564627628604e-09,
      "loss": 2.2405,
      "step": 8840
    },
    {
      "epoch": 0.9942703067071116,
      "grad_norm": 7.459133625030518,
      "learning_rate": 8.516270176850416e-10,
      "loss": 1.6819,
      "step": 8850
    },
    {
      "epoch": 0.9953937759802269,
      "grad_norm": 8.14947509765625,
      "learning_rate": 5.555787296046555e-10,
      "loss": 1.7773,
      "step": 8860
    },
    {
      "epoch": 0.9965172452533423,
      "grad_norm": 8.631671905517578,
      "learning_rate": 3.225153282493398e-10,
      "loss": 1.7547,
      "step": 8870
    },
    {
      "epoch": 0.9976407145264578,
      "grad_norm": 10.266185760498047,
      "learning_rate": 1.5243974983980558e-10,
      "loss": 1.8686,
      "step": 8880
    },
    {
      "epoch": 0.9987641837995731,
      "grad_norm": 9.981770515441895,
      "learning_rate": 4.5354137052089354e-11,
      "loss": 1.8473,
      "step": 8890
    },
    {
      "epoch": 0.9998876530726885,
      "grad_norm": 6.714270114898682,
      "learning_rate": 1.2598389920182031e-12,
      "loss": 1.7959,
      "step": 8900
    }
  ],
  "logging_steps": 10,
  "max_steps": 8901,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7087293621338112.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
